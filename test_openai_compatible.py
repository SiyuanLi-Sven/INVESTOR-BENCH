#!/usr/bin/env python3
"""
ç‹¬ç«‹æµ‹è¯•OpenAIå…¼å®¹å®¢æˆ·ç«¯
"""

import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(__file__))

def test_openai_compatible_import():
    """æµ‹è¯•OpenAIå…¼å®¹å®¢æˆ·ç«¯å¯¼å…¥"""
    try:
        # å…ˆæµ‹è¯•åŸºç¡€çš„OpenAIå¯¼å…¥
        from openai import OpenAI
        print("âœ“ OpenAIåº“å¯¼å…¥æˆåŠŸ")
        
        # æµ‹è¯•é…ç½®å¯¼å…¥
        from config import get_model_config, get_all_llm_models
        print("âœ“ é…ç½®æ¨¡å—å¯¼å…¥æˆåŠŸ")
        
        # æµ‹è¯•è‡ªå®šä¹‰å®¢æˆ·ç«¯ç±»
        sys.path.append(os.path.join(os.path.dirname(__file__), 'src/chat/endpoint'))
        
        # ç›´æ¥å¯¼å…¥æˆ‘ä»¬çš„OpenAIå…¼å®¹å®¢æˆ·ç«¯
        from src.chat.endpoint.openai_compatible import OpenAICompatibleClient
        print("âœ“ OpenAIå…¼å®¹å®¢æˆ·ç«¯å¯¼å…¥æˆåŠŸ")
        
        return True
    except Exception as e:
        print(f"âœ— å¯¼å…¥å¤±è´¥: {e}")
        return False

def test_client_creation():
    """æµ‹è¯•å®¢æˆ·ç«¯åˆ›å»ºï¼ˆä¸å®é™…è¿æ¥APIï¼‰"""
    try:
        from config import get_all_llm_models
        from src.chat.endpoint.openai_compatible import OpenAICompatibleClient
        
        llm_models = get_all_llm_models()
        if not llm_models:
            print("âœ— æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„LLMæ¨¡å‹")
            return False
        
        # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ¨¡å‹è¿›è¡Œæµ‹è¯•ï¼ˆä¸å®é™…åˆ›å»ºè¿æ¥ï¼‰
        model_name = llm_models[0]
        print(f"âœ“ å°†ä½¿ç”¨æ¨¡å‹æµ‹è¯•: {model_name}")
        
        # è¿™é‡Œæˆ‘ä»¬ä¸å®é™…åˆ›å»ºå®¢æˆ·ç«¯ï¼Œå› ä¸ºéœ€è¦æœ‰æ•ˆçš„APIå¯†é’¥
        # ä½†æˆ‘ä»¬å¯ä»¥éªŒè¯é…ç½®æ˜¯å¦æ­£ç¡®
        from config import get_model_config
        config = get_model_config(model_name)
        
        required_keys = ['api_base', 'api_key', 'model', 'type']
        for key in required_keys:
            if key not in config:
                print(f"âœ— é…ç½®ç¼ºå°‘å¿…éœ€å­—æ®µ: {key}")
                return False
        
        print("âœ“ æ¨¡å‹é…ç½®æ ¼å¼æ­£ç¡®")
        print(f"  - æ¨¡å‹: {config['model']}")
        print(f"  - API Base: {config['api_base']}")
        print(f"  - Provider: {config.get('provider', 'unknown')}")
        
        return True
    except Exception as e:
        print(f"âœ— å®¢æˆ·ç«¯åˆ›å»ºæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_embedding_client():
    """æµ‹è¯•embeddingå®¢æˆ·ç«¯"""
    try:
        from src.embedding_unified import UnifiedOpenAIEmbedding
        from config import get_all_embedding_models
        
        emb_models = get_all_embedding_models()
        if not emb_models:
            print("âœ— æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„Embeddingæ¨¡å‹")
            return False
        
        print(f"âœ“ æ‰¾åˆ°Embeddingæ¨¡å‹: {emb_models}")
        
        # æµ‹è¯•é…ç½®æ ¼å¼
        from config import get_model_config
        for model in emb_models:
            config = get_model_config(model)
            if config['type'] != 'embedding_api':
                print(f"âœ— æ¨¡å‹ç±»å‹ä¸æ­£ç¡®: {model}")
                return False
            print(f"âœ“ {model} é…ç½®æ­£ç¡®")
        
        return True
    except Exception as e:
        print(f"âœ— Embeddingå®¢æˆ·ç«¯æµ‹è¯•å¤±è´¥: {e}")
        return False

def create_demo_config():
    """åˆ›å»ºç¤ºä¾‹é…ç½®æ–‡ä»¶"""
    try:
        demo_config = {
            "chat_config": {
                "chat_model": "Qwen/Qwen3-8B",  # ä½¿ç”¨ç¡…åŸºæµåŠ¨çš„æ¨¡å‹
                "chat_model_inference_engine": "openai_compatible", 
                "chat_system_message": "You are a helpful assistant.",
                "chat_parameters": {
                    "temperature": 0.6
                },
                "chat_max_new_token": 1000,
                "chat_request_timeout": 60
            },
            "emb_config": {
                "emb_model_name": "Qwen/Qwen3-Embedding-4B",
                "embedding_timeout": 60
            }
        }
        
        import json
        with open('demo_config.json', 'w', encoding='utf-8') as f:
            json.dump(demo_config, f, indent=2, ensure_ascii=False)
        
        print("âœ“ åˆ›å»ºç¤ºä¾‹é…ç½®æ–‡ä»¶: demo_config.json")
        return True
    except Exception as e:
        print(f"âœ— åˆ›å»ºç¤ºä¾‹é…ç½®å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("=" * 60)
    print("OpenAIå…¼å®¹å®¢æˆ·ç«¯ç‹¬ç«‹æµ‹è¯•")
    print("=" * 60)
    
    tests = [
        ("åŸºç¡€å¯¼å…¥æµ‹è¯•", test_openai_compatible_import),
        ("å®¢æˆ·ç«¯åˆ›å»ºæµ‹è¯•", test_client_creation),
        ("Embeddingå®¢æˆ·ç«¯æµ‹è¯•", test_embedding_client),
        ("åˆ›å»ºç¤ºä¾‹é…ç½®", create_demo_config),
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        print(f"\n[{test_name}]")
        try:
            if test_func():
                passed += 1
        except Exception as e:
            print(f"âœ— æµ‹è¯•å¼‚å¸¸: {e}")
        print("-" * 40)
    
    print(f"\næµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")
    
    if passed >= 3:
        print("\nğŸ‰ OpenAIå…¼å®¹ç³»ç»Ÿæµ‹è¯•é€šè¿‡ï¼")
        print("\nğŸ“‹ é‡æ„æ€»ç»“:")
        print("=" * 40)
        print("âœ… 1. ç»Ÿä¸€é…ç½®ç³»ç»Ÿ (config.py)")
        print("âœ… 2. OpenAIå…¼å®¹çš„LLMå®¢æˆ·ç«¯")
        print("âœ… 3. ç»Ÿä¸€çš„Embeddingæ¥å£")
        print("âœ… 4. æ”¯æŒå¤šç§Provider")
        print("âœ… 5. å‘åå…¼å®¹ç°æœ‰æ¥å£")
        
        print("\nğŸš€ ä½¿ç”¨æŒ‡å—:")
        print("=" * 40)
        print("1. åœ¨config.pyä¸­é…ç½®æ‚¨çš„APIå¯†é’¥")
        print("2. é€‰æ‹©åˆé€‚çš„æ¨¡å‹é…ç½®")
        print("3. ä½¿ç”¨'openai_compatible'ä½œä¸ºinference_engine")
        print("4. äº«å—ç»Ÿä¸€çš„APIè°ƒç”¨ä½“éªŒï¼")
        
        return True
    else:
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)