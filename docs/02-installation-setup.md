# âš™ï¸ å®‰è£…ä¸é…ç½®

[è¿”å›æ–‡æ¡£ç´¢å¼•](./README.md)

## ğŸ¯ ç¯å¢ƒè¦æ±‚

### ç³»ç»Ÿè¦æ±‚
- **æ“ä½œç³»ç»Ÿ**: Linuxã€macOSã€Windows (æ¨è Linux/macOS)
- **Pythonç‰ˆæœ¬**: Python 3.8+
- **å†…å­˜**: è‡³å°‘ 8GB RAM (æ¨è 16GB+)
- **å­˜å‚¨**: è‡³å°‘ 10GB å¯ç”¨ç©ºé—´
- **ç½‘ç»œ**: ç¨³å®šçš„äº’è”ç½‘è¿æ¥(ç”¨äºAPIè°ƒç”¨)

### ç¡¬ä»¶è¦æ±‚
- **CPU**: å¤šæ ¸å¤„ç†å™¨ (æ¨è 8æ ¸+)
- **GPU**: å¯é€‰ï¼Œå¦‚æœä½¿ç”¨æœ¬åœ°VLLMæ¨ç†
- **ç½‘ç»œ**: å¸¦å®½è¶³å¤Ÿæ”¯æŒAPIè°ƒç”¨

## ğŸ“¦ ä¾èµ–å®‰è£…

### 1. å…‹éš†é¡¹ç›®

```bash
git clone <repository_url>
cd INVESTOR-BENCH
```

### 2. Pythonç¯å¢ƒè®¾ç½®

#### ä½¿ç”¨conda (æ¨è)

```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
conda create -n investor-bench python=3.10
conda activate investor-bench

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

#### ä½¿ç”¨pip

```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv investor-bench
source investor-bench/bin/activate  # Linux/macOS
# investor-bench\Scripts\activate  # Windows

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

### 3. éªŒè¯å®‰è£…

```bash
# åŸºç¡€åŠŸèƒ½æµ‹è¯•
python test_simplified.py

# APIæ¥å£æµ‹è¯•  
python test_openai_compatible.py
```

## ğŸ”‘ APIå¯†é’¥é…ç½®

### æ–¹æ³•1: config.pyé…ç½® (æ¨è)

åœ¨ `config.py` ä¸­é…ç½®æ‚¨çš„APIå¯†é’¥ï¼š

```python
MODEL_CONFIGS = {
    # ç¡…åŸºæµåŠ¨API (æ¨èï¼Œæˆæœ¬ä½)
    "Qwen/Qwen3-8B": {
        "type": "llm_api",
        "model": "Qwen/Qwen3-8B",
        "api_base": "https://api.siliconflow.cn/v1",
        "api_key": "sk-your-siliconflow-api-key-here",  # ğŸ”‘ æ›¿æ¢ä¸ºå®é™…å¯†é’¥
        "provider": "siliconflow"
    },
    
    # OpenAI API
    "gpt-4": {
        "type": "llm_api",
        "model": "gpt-4",
        "api_base": "https://api.openai.com/v1",
        "api_key": "sk-your-openai-api-key-here",  # ğŸ”‘ æ›¿æ¢ä¸ºå®é™…å¯†é’¥
        "provider": "openai"
    },
    
    # Embeddingæ¨¡å‹
    "Qwen/Qwen3-Embedding-4B": {
        "type": "embedding_api",
        "model": "Qwen/Qwen3-Embedding-4B",
        "api_base": "https://api.siliconflow.cn/v1",
        "api_key": "sk-your-siliconflow-api-key-here",  # ğŸ”‘ æ›¿æ¢ä¸ºå®é™…å¯†é’¥
        "provider": "siliconflow"
    }
}
```

### æ–¹æ³•2: ç¯å¢ƒå˜é‡é…ç½®

åˆ›å»º `.env` æ–‡ä»¶ï¼š

```bash
# OpenAIé…ç½®
OPENAI_API_KEY=sk-your-openai-api-key-here

# HuggingFaceé…ç½® (å¦‚æœéœ€è¦ä¸‹è½½æ¨¡å‹)
HUGGING_FACE_HUB_TOKEN=hf-your-huggingface-token-here

# ç¡…åŸºæµåŠ¨é…ç½®
SILICONFLOW_API_KEY=sk-your-siliconflow-api-key-here

# Anthropicé…ç½®
ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here
```

### APIå¯†é’¥è·å–æŒ‡å—

#### 1. ç¡…åŸºæµåŠ¨ (æ¨è)
- è®¿é—®: https://cloud.siliconflow.cn/
- æ³¨å†Œè´¦å·å¹¶åˆ›å»ºAPIå¯†é’¥
- æˆæœ¬ä½ï¼Œå“åº”å¿«ï¼Œæ”¯æŒå¤šç§å¼€æºæ¨¡å‹

#### 2. OpenAI
- è®¿é—®: https://platform.openai.com/
- åˆ›å»ºè´¦å·å¹¶ç”ŸæˆAPI Key
- éœ€è¦ç»‘å®šæ”¯ä»˜æ–¹å¼

#### 3. HuggingFace
- è®¿é—®: https://huggingface.co/settings/tokens
- åˆ›å»ºAccess Token
- ç”¨äºä¸‹è½½å¼€æºæ¨¡å‹

## ğŸ—„ï¸ æ•°æ®åº“é…ç½®

### Qdrantå‘é‡æ•°æ®åº“

#### Dockeréƒ¨ç½² (æ¨è)

```bash
# æ‹‰å–é•œåƒ
docker pull qdrant/qdrant

# å¯åŠ¨æœåŠ¡
docker run -p 6333:6333 -p 6334:6334 \
    -v $(pwd)/qdrant_storage:/qdrant/storage:z \
    qdrant/qdrant
```

#### æœ¬åœ°å®‰è£…

```bash
# ä½¿ç”¨cargoå®‰è£…
cargo install qdrant

# æˆ–ä¸‹è½½äºŒè¿›åˆ¶æ–‡ä»¶
wget https://github.com/qdrant/qdrant/releases/latest/download/qdrant
chmod +x qdrant
./qdrant --config-path config/production.yaml
```

#### é…ç½®éªŒè¯

```bash
# æ£€æŸ¥æœåŠ¡çŠ¶æ€
curl -X GET "http://localhost:6333/collections"

# åº”è¯¥è¿”å›ç©ºçš„collectionsåˆ—è¡¨
# {"result":{"collections":[]},"status":"ok","time":0.000}
```

### æ•°æ®åº“è¿æ¥é…ç½®

åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½®å‘é‡æ•°æ®åº“è¿æ¥ï¼š

```json
{
  "agent_config": {
    "memory_db_config": {
      "memory_db_endpoint": "http://localhost:6333"
    }
  }
}
```

## ğŸ¤– æ¨¡å‹æœåŠ¡é…ç½®

### æœ¬åœ°VLLMéƒ¨ç½² (å¯é€‰)

å¦‚æœéœ€è¦ä½¿ç”¨æœ¬åœ°LLMæ¨ç†ï¼š

#### 1. å®‰è£…VLLM

```bash
# ä½¿ç”¨pipå®‰è£…
pip install vllm

# æˆ–ä½¿ç”¨Docker
docker pull vllm/vllm-openai:latest
```

#### 2. å¯åŠ¨VLLMæœåŠ¡

```bash
# å¯åŠ¨è„šæœ¬
bash scripts/start_vllm.sh

# æˆ–æ‰‹åŠ¨å¯åŠ¨
python -m vllm.entrypoints.openai.api_server \
    --model meta-llama/Meta-Llama-3.1-8B-Instruct \
    --port 8000 \
    --tensor-parallel-size 2
```

#### 3. é…ç½®æ¨¡å‹

åœ¨ `config.py` ä¸­æ·»åŠ æœ¬åœ°æ¨¡å‹ï¼š

```python
"local-vllm": {
    "type": "llm_api",
    "model": "meta-llama/Meta-Llama-3.1-8B-Instruct",
    "api_base": "http://0.0.0.0:8000/v1",
    "api_key": "EMPTY",
    "provider": "vllm"
}
```

### äº‘ç«¯APIæœåŠ¡

ä½¿ç”¨äº‘ç«¯APIæœåŠ¡æ›´ç®€å•ï¼Œåªéœ€é…ç½®APIå¯†é’¥å³å¯ã€‚

## ğŸ”§ ç³»ç»Ÿé…ç½®éªŒè¯

### 1. è¿è¡Œå…¨é¢æµ‹è¯•

```bash
# åŸºç¡€é…ç½®æµ‹è¯•
python test_simplified.py

# é¢„æœŸè¾“å‡º
# ==================================================
# ç»Ÿä¸€é…ç½®ç³»ç»Ÿ - ç®€åŒ–æµ‹è¯•
# ==================================================
# 
# [åŸºç¡€é…ç½®åŠŸèƒ½]
# âœ“ é…ç½®æ–‡ä»¶å¯¼å…¥æˆåŠŸ
# âœ“ æ‰¾åˆ° 4 ä¸ªLLMæ¨¡å‹
# âœ“ æ‰¾åˆ° 1 ä¸ªEmbeddingæ¨¡å‹
# âœ“ æˆåŠŸè·å–æ¨¡å‹é…ç½®
# ------------------------------
# 
# æµ‹è¯•ç»“æœ: 4/5 é€šè¿‡
# ğŸ‰ æ ¸å¿ƒåŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼
```

### 2. APIè¿æ¥æµ‹è¯•

```bash
# OpenAIå…¼å®¹æ¥å£æµ‹è¯•
python test_openai_compatible.py

# é¢„æœŸè¾“å‡ºåº”æ˜¾ç¤ºæˆåŠŸçš„é…ç½®å’Œè¿æ¥
```

### 3. æœåŠ¡çŠ¶æ€æ£€æŸ¥

```bash
# æ£€æŸ¥Qdrant
curl -X GET "http://localhost:6333/collections"

# æ£€æŸ¥VLLM (å¦‚æœä½¿ç”¨)
curl -X GET "http://localhost:8000/health"

# æ£€æŸ¥GPUçŠ¶æ€ (å¦‚æœä½¿ç”¨)
nvidia-smi
```

## ğŸ“ ç›®å½•ç»“æ„

å®‰è£…å®Œæˆåçš„é¡¹ç›®ç»“æ„ï¼š

```
INVESTOR-BENCH/
â”œâ”€â”€ config.py                    # ğŸ”¥ ç»Ÿä¸€é…ç½®æ–‡ä»¶
â”œâ”€â”€ configs/                     # é…ç½®æ–‡ä»¶ç›®å½•
â”‚   â”œâ”€â”€ main.json               # åŸå§‹é…ç½®
â”‚   â””â”€â”€ main_unified.json       # ç»Ÿä¸€APIé…ç½®
â”œâ”€â”€ src/                         # æºä»£ç 
â”‚   â”œâ”€â”€ chat/                   # LLMæ¥å£
â”‚   â”œâ”€â”€ embedding_unified.py    # ç»Ÿä¸€Embeddingæ¥å£
â”‚   â””â”€â”€ ...
â”œâ”€â”€ data/                        # å¸‚åœºæ•°æ®
â”œâ”€â”€ results/                     # å®éªŒç»“æœ
â”œâ”€â”€ docs/                        # é¡¹ç›®æ–‡æ¡£
â”œâ”€â”€ requirements.txt             # Pythonä¾èµ–
â”œâ”€â”€ run.py                      # ä¸»ç¨‹åºå…¥å£
â””â”€â”€ test_*.py                   # æµ‹è¯•è„šæœ¬
```

## ğŸš€ å¿«é€ŸéªŒè¯

### åˆ›å»ºæµ‹è¯•é…ç½®

```bash
# ä½¿ç”¨æä¾›çš„ç»Ÿä¸€é…ç½®æ¨¡æ¿
cp configs/main_unified.json configs/my_test.json

# ç¼–è¾‘é…ç½®æ–‡ä»¶ï¼Œæ›´æ–°APIå¯†é’¥
vim configs/my_test.json
```

### è¿è¡Œç®€å•æµ‹è¯•

```bash
# éªŒè¯é…ç½®
python -c "
import json
config = json.load(open('configs/my_test.json'))
print('âœ“ Configuration loaded successfully')
print(f'LLM Model: {config[\"chat_config\"][\"chat_model\"]}')
print(f'Embedding Model: {config[\"emb_config\"][\"emb_model_name\"]}')
"

# æµ‹è¯•ä¾èµ–
python -c "
import openai, qdrant_client, loguru
from src import FinMemAgent, MarketEnv
print('âœ“ All dependencies imported successfully')
"
```

## ğŸ” å®‰å…¨æ³¨æ„äº‹é¡¹

### APIå¯†é’¥å®‰å…¨
1. **ä¸è¦æäº¤å¯†é’¥**: å°† `.env` å’ŒåŒ…å«å¯†é’¥çš„é…ç½®æ–‡ä»¶æ·»åŠ åˆ° `.gitignore`
2. **å®šæœŸè½®æ¢**: å®šæœŸæ›´æ–°APIå¯†é’¥
3. **æƒé™æ§åˆ¶**: ä½¿ç”¨æœ€å°æƒé™åŸåˆ™é…ç½®APIå¯†é’¥

### ç½‘ç»œå®‰å…¨
1. **é˜²ç«å¢™é…ç½®**: ç¡®ä¿Qdrantç«¯å£(6333)ä¸å¯¹å¤–å¼€æ”¾
2. **HTTPSä½¿ç”¨**: ç”Ÿäº§ç¯å¢ƒä½¿ç”¨HTTPSè¿æ¥
3. **è®¿é—®æ§åˆ¶**: é™åˆ¶APIè®¿é—®æ¥æº

## ğŸ› å¸¸è§é—®é¢˜

### 1. ä¾èµ–å®‰è£…å¤±è´¥
```bash
# æ¸…ç†pipç¼“å­˜
pip cache purge

# ä½¿ç”¨å›½å†…é•œåƒæº
pip install -i https://pypi.tuna.tsinghua.edu.cn/simple -r requirements.txt
```

### 2. APIè¿æ¥å¤±è´¥
```bash
# æ£€æŸ¥ç½‘ç»œè¿æ¥
curl -I https://api.openai.com/v1/models

# éªŒè¯APIå¯†é’¥æ ¼å¼
python -c "
import openai
client = openai.OpenAI(api_key='your-api-key')
print('âœ“ API key format valid')
"
```

### 3. Qdrantè¿æ¥é—®é¢˜
```bash
# æ£€æŸ¥ç«¯å£å ç”¨
netstat -tulpn | grep 6333

# é‡å¯QdrantæœåŠ¡
docker restart <qdrant_container_id>
```

## ğŸ“š ä¸‹ä¸€æ­¥

å®‰è£…å®Œæˆåï¼Œè¯·ç»§ç»­é˜…è¯»ï¼š

- [å¿«é€Ÿå¼€å§‹](./03-quick-start.md) - è¿è¡Œç¬¬ä¸€ä¸ªå®éªŒ
- [é…ç½®ç³»ç»Ÿ](./04-configuration.md) - è¯¦ç»†é…ç½®é€‰é¡¹
- [CLIå‚è€ƒ](./10-cli-reference.md) - å‘½ä»¤è¡Œä½¿ç”¨æŒ‡å—

---

[â† ä¸Šä¸€ç« : é¡¹ç›®æ¦‚è¿°](./01-project-overview.md) | [ä¸‹ä¸€ç« : å¿«é€Ÿå¼€å§‹ â†’](./03-quick-start.md)