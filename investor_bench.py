#!/usr/bin/env python3
"""
INVESTOR-BENCH - åŸºäºLLMçš„æ™ºèƒ½æŠ•èµ„å›æµ‹ç³»ç»Ÿ
æ”¯æŒOpenAIå…¼å®¹APIçš„ç»Ÿä¸€å‘½ä»¤è¡Œæ¥å£

ä½¿ç”¨æ–¹æ³•:
python investor_bench.py --symbol JNJ --start-date 2020-07-02 --end-date 2020-07-10 --mode warmup
python investor_bench.py --symbol JNJ --model gpt-4 --api-key sk-xxx --api-base https://api.openai.com/v1
"""

import argparse
import json
import os
import sys
import time
from datetime import datetime, date
from pathlib import Path
from typing import Dict, List, Optional, Any
import traceback

import numpy as np
from dotenv import load_dotenv
from loguru import logger
from openai import OpenAI
import httpx

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

class InvestorBench:
    """INVESTOR-BENCHä¸»æ§åˆ¶å™¨"""
    
    def __init__(self, args):
        self.args = args
        self.start_time = datetime.now()
        
        # è®¾ç½®è¿è¡Œç›®å½• - å¸¦æ—¶é—´æˆ³å’Œæ¨¡å‹åç§°
        timestamp = self.start_time.strftime("%y%m%d_%H%M%S")
        model_name = self._clean_model_name(args.model)
        self.run_dir = Path("results") / f"{timestamp}_{model_name}_{args.symbol}"
        self.run_dir.mkdir(parents=True, exist_ok=True)
        
        # è®¾ç½®è¯¦ç»†çš„æ—¥å¿—
        log_file = self.run_dir / "run.log"
        logger.add(log_file, level="TRACE", format="{time:YYYY-MM-DD HH:mm:ss} | {level} | {message}")
        
        # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
        self.client = self._init_openai_client()
        
        # åˆå§‹åŒ–APIç»Ÿè®¡
        self.api_stats = {
            "chat_calls": 0,
            "embedding_calls": 0,
            "total_tokens": 0,
            "errors": 0
        }
        
        # ç®€åŒ–çš„è®°å¿†å­˜å‚¨
        self.memories = []
        
        logger.info(f"ğŸš€ INVESTOR-BENCHå¯åŠ¨ - è¿è¡Œç›®å½•: {self.run_dir}")
        
    def _clean_model_name(self, model: str) -> str:
        """æ¸…ç†æ¨¡å‹åç§°ç”¨äºæ–‡ä»¶è·¯å¾„"""
        return model.replace("/", "_").replace(":", "_").replace(" ", "_")
    
    def _init_openai_client(self) -> OpenAI:
        """åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯"""
        # ä¼˜å…ˆçº§ï¼šå‘½ä»¤è¡Œå‚æ•° > ç¯å¢ƒå˜é‡ > é»˜è®¤å€¼
        api_key = self.args.api_key or os.getenv('OPENAI_API_KEY')
        api_base = self.args.api_base or os.getenv('OPENAI_API_BASE', 'https://api.siliconflow.cn/v1')
        
        if not api_key:
            raise ValueError("âŒ APIå¯†é’¥æœªè®¾ç½®ï¼è¯·é€šè¿‡--api-keyå‚æ•°æˆ–OPENAI_API_KEYç¯å¢ƒå˜é‡æä¾›")
        
        logger.info(f"ğŸ”§ OpenAIå®¢æˆ·ç«¯é…ç½®:")
        logger.info(f"   æ¨¡å‹: {self.args.model}")
        logger.info(f"   API Base: {api_base}")
        logger.info(f"   API Key: {api_key[:10]}...")
        
        return OpenAI(api_key=api_key, base_url=api_base)
    
    def call_llm(self, prompt: str, system_message: str = None, max_tokens: int = 1024) -> Dict[str, Any]:
        """è°ƒç”¨LLM API withç»Ÿè®¡å’Œé”™è¯¯å¤„ç†"""
        messages = []
        if system_message:
            messages.append({"role": "system", "content": system_message})
        messages.append({"role": "user", "content": prompt})
        
        try:
            self.api_stats["chat_calls"] += 1
            
            response = self.client.chat.completions.create(
                model=self.args.model,
                messages=messages,
                temperature=0.6,
                max_tokens=max_tokens,
                response_format={"type": "json_object"}
            )
            
            # æ›´æ–°ç»Ÿè®¡
            if hasattr(response, 'usage') and response.usage:
                self.api_stats["total_tokens"] += response.usage.total_tokens
            
            content = response.choices[0].message.content
            return json.loads(content)
            
        except Exception as e:
            self.api_stats["errors"] += 1
            logger.error(f"âŒ LLMè°ƒç”¨å¤±è´¥: {e}")
            return {"error": str(e), "action": "HOLD", "confidence": 0.0, "reasoning": "APIè°ƒç”¨å¤±è´¥"}
    
    def call_embedding(self, text: str) -> List[float]:
        """è°ƒç”¨Embedding API"""
        try:
            self.api_stats["embedding_calls"] += 1
            
            # ä½¿ç”¨å›ºå®šçš„SiliconFlow embedding
            embed_client = OpenAI(
                api_key=os.getenv('OPENAI_API_KEY'),
                base_url='https://api.siliconflow.cn/v1'
            )
            
            response = embed_client.embeddings.create(
                model="Qwen/Qwen3-Embedding-4B",
                input=text
            )
            
            return response.data[0].embedding
            
        except Exception as e:
            logger.error(f"âŒ Embeddingè°ƒç”¨å¤±è´¥: {e}")
            return [0.0] * 2560  # è¿”å›é»˜è®¤ç»´åº¦çš„é›¶å‘é‡
    
    def load_market_data(self) -> List[Dict]:
        """åŠ è½½å¸‚åœºæ•°æ®"""
        data_file = Path("data") / f"{self.args.symbol.lower()}.json"
        
        if not data_file.exists():
            raise FileNotFoundError(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_file}")
        
        with open(data_file, 'r', encoding='utf-8') as f:
            raw_data = json.load(f)
        
        # è½¬æ¢æ•°æ®æ ¼å¼ï¼šä»{date: {data}} è½¬ä¸º [{date, data}]
        data = []
        for date_str, day_info in raw_data.items():
            data.append({
                'date': date_str,
                'symbol': self.args.symbol,
                'price': day_info.get('prices', 0),
                'news': day_info.get('news', []),
                'filing_k': day_info.get('10k', []),
                'filing_q': day_info.get('10q', [])
            })
        
        # æŒ‰æ—¥æœŸæ’åº
        data.sort(key=lambda x: x['date'])
        
        # è¿‡æ»¤æ—¥æœŸèŒƒå›´
        filtered_data = []
        start_date = datetime.strptime(self.args.start_date, '%Y-%m-%d').date()
        end_date = datetime.strptime(self.args.end_date, '%Y-%m-%d').date()
        
        for day_data in data:
            day_date = datetime.strptime(day_data['date'], '%Y-%m-%d').date()
            if start_date <= day_date <= end_date:
                filtered_data.append(day_data)
        
        logger.info(f"ğŸ“Š åŠ è½½æ•°æ®: {len(filtered_data)}å¤©, {start_date} è‡³ {end_date}")
        return filtered_data
    
    def investment_decision(self, day_data: Dict) -> Dict[str, Any]:
        """åˆ¶å®šæŠ•èµ„å†³ç­–"""
        symbol = day_data.get('symbol', self.args.symbol)
        price = day_data.get('price', 0)
        news = day_data.get('news', [])
        date_str = day_data['date']
        
        # æ„å»ºä¸Šä¸‹æ–‡
        news_text = "\\n".join([f"- {item}" for item in news[:5]])  # æœ€å¤š5æ¡æ–°é—»
        memory_context = "\\n".join([f"è®°å¿†: {mem}" for mem in self.memories[-3:]])  # æœ€è¿‘3æ¡è®°å¿†
        
        # æ„å»ºå†³ç­–prompt
        prompt = f"""
è¯·åŸºäºä»¥ä¸‹ä¿¡æ¯ä¸º{symbol}åˆ¶å®šæŠ•èµ„å†³ç­–ï¼š

## å½“å‰å¸‚åœºä¿¡æ¯
- è‚¡ç¥¨ä»£ç : {symbol}
- å½“å‰ä»·æ ¼: ${price:.2f}
- åˆ†ææ—¥æœŸ: {date_str}
- è¿è¡Œæ¨¡å¼: {self.args.mode}

## ä»Šæ—¥æ–°é—»
{news_text if news_text.strip() else "æ— é‡è¦æ–°é—»"}

## å†å²è®°å¿†
{memory_context if memory_context.strip() else "æš‚æ— å†å²è®°å¿†"}

## ä¸“ä¸šèƒŒæ™¯
ä½ æ˜¯{symbol}çš„ä¸“ä¸šæŠ•èµ„åˆ†æå¸ˆï¼Œè¯·åŸºäºä¸Šè¿°ä¿¡æ¯åšå‡ºæŠ•èµ„å†³ç­–ã€‚

## è¦æ±‚
è¯·è¿”å›æ ‡å‡†JSONæ ¼å¼:
{{
    "action": "BUY, SELL, æˆ– HOLD",
    "confidence": 0.0åˆ°1.0çš„ç½®ä¿¡åº¦æ•°å€¼,
    "reasoning": "è¯¦ç»†çš„å†³ç­–ç†ç”±è¯´æ˜",
    "key_factors": ["å½±å“å†³ç­–çš„å…³é”®å› ç´ 1", "å…³é”®å› ç´ 2", "å…³é”®å› ç´ 3"],
    "memory_update": "éœ€è¦è®°ä½çš„é‡è¦ä¿¡æ¯(å¯é€‰)"
}}
"""
        
        system_message = f"ä½ æ˜¯ä¸“ä¸šçš„{symbol}æŠ•èµ„åˆ†æå¸ˆã€‚åœ¨{self.args.mode}æ¨¡å¼ä¸‹æä¾›æŠ•èµ„å»ºè®®ã€‚å§‹ç»ˆè¿”å›æœ‰æ•ˆJSONã€‚"
        
        logger.info(f"ğŸ§  åˆ†æ {symbol} - {date_str}")
        decision = self.call_llm(prompt, system_message, max_tokens=1024)
        
        # æ›´æ–°è®°å¿†
        if decision.get("memory_update"):
            self.memories.append(f"{date_str}: {decision['memory_update']}")
            if len(self.memories) > 10:  # é™åˆ¶è®°å¿†æ¡æ•°
                self.memories.pop(0)
        
        return decision
    
    def run_backtest(self):
        """è¿è¡Œå›æµ‹"""
        logger.info(f"ğŸ¯ å¼€å§‹å›æµ‹ - æ¨¡å¼: {self.args.mode}")
        
        # åŠ è½½å¸‚åœºæ•°æ®
        market_data = self.load_market_data()
        
        if not market_data:
            raise ValueError("âŒ æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ—¥æœŸèŒƒå›´çš„æ•°æ®")
        
        results = []
        portfolio_value = 10000.0  # åˆå§‹èµ„é‡‘
        position = 0  # æŒä»“æ•°é‡
        
        for i, day_data in enumerate(market_data):
            logger.info(f"ğŸ“… å¤„ç†ç¬¬{i+1}/{len(market_data)}å¤©: {day_data['date']}")
            
            # åˆ¶å®šæŠ•èµ„å†³ç­–
            decision = self.investment_decision(day_data)
            
            # æ¨¡æ‹Ÿæ‰§è¡Œäº¤æ˜“
            price = day_data.get('price', 0)
            action = decision.get('action', 'HOLD')
            
            if action == 'BUY' and position == 0:
                position = portfolio_value / price
                portfolio_value = 0
                logger.info(f"ğŸ’° ä¹°å…¥ {position:.2f}è‚¡ @ ${price:.2f}")
            elif action == 'SELL' and position > 0:
                portfolio_value = position * price
                position = 0
                logger.info(f"ğŸ’¸ å–å‡ºè·å¾— ${portfolio_value:.2f}")
            
            # è®¡ç®—å½“å‰ä»·å€¼
            current_value = portfolio_value + (position * price)
            
            result = {
                "date": day_data['date'],
                "symbol": self.args.symbol,
                "price": price,
                "decision": decision,
                "position": position,
                "portfolio_value": current_value,
                "daily_return": 0 if i == 0 else (current_value / results[-1]["portfolio_value"] - 1)
            }
            
            results.append(result)
            
            # è¾“å‡ºè¿›åº¦
            confidence = decision.get('confidence', 0)
            reasoning = decision.get('reasoning', 'N/A')
            logger.info(f"ğŸ¯ å†³ç­–: {action} (ç½®ä¿¡åº¦: {confidence:.2f})")
            logger.info(f"ğŸ“ æŠ•èµ„ç»„åˆä»·å€¼: ${current_value:.2f}")
            logger.info(f"ğŸ’¡ ç†ç”±: {reasoning[:100]}...")
            logger.info("-" * 60)
        
        return results
    
    def calculate_trading_metrics(self, results: List[Dict]) -> Dict[str, float]:
        """è®¡ç®—äº¤æ˜“æŒ‡æ ‡"""
        if len(results) < 2:
            return {
                "total_return": 0.0,
                "annualized_return": 0.0,
                "volatility": 0.0,
                "sharpe_ratio": 0.0,
                "max_drawdown": 0.0,
                "win_rate": 0.0,
                "total_trades": 0
            }
        
        # æå–ä»·æ ¼å’ŒæŠ•èµ„ç»„åˆä»·å€¼æ•°æ®
        prices = [r["price"] for r in results]
        portfolio_values = [r["portfolio_value"] for r in results]
        actions = [r["decision"].get("action", "HOLD") for r in results]
        
        # è®¡ç®—æ¯æ—¥æ”¶ç›Šç‡
        daily_returns = []
        for i in range(1, len(portfolio_values)):
            daily_return = (portfolio_values[i] / portfolio_values[i-1]) - 1
            daily_returns.append(daily_return)
        
        # åŸºæœ¬æŒ‡æ ‡
        total_return = (portfolio_values[-1] / portfolio_values[0]) - 1
        trading_days = len(results)
        annualized_return = ((1 + total_return) ** (252 / trading_days)) - 1 if trading_days > 0 else 0
        
        # æ³¢åŠ¨ç‡
        volatility = np.std(daily_returns) * np.sqrt(252) if daily_returns else 0
        
        # å¤æ™®æ¯”ç‡ (å‡è®¾æ— é£é™©åˆ©ç‡ä¸º0)
        sharpe_ratio = annualized_return / volatility if volatility > 0 else 0
        
        # æœ€å¤§å›æ’¤
        max_drawdown = self._calculate_max_drawdown(portfolio_values)
        
        # äº¤æ˜“ç»Ÿè®¡
        buy_actions = actions.count("BUY")
        sell_actions = actions.count("SELL")
        total_trades = buy_actions + sell_actions
        
        # èƒœç‡è®¡ç®— (ç®€åŒ–ç‰ˆæœ¬)
        profitable_days = sum(1 for r in daily_returns if r > 0)
        win_rate = profitable_days / len(daily_returns) if daily_returns else 0
        
        return {
            "total_return": total_return,
            "annualized_return": annualized_return,
            "volatility": volatility,
            "sharpe_ratio": sharpe_ratio,
            "max_drawdown": max_drawdown,
            "win_rate": win_rate,
            "total_trades": total_trades,
            "buy_actions": buy_actions,
            "sell_actions": sell_actions
        }
    
    def _calculate_max_drawdown(self, portfolio_values: List[float]) -> float:
        """è®¡ç®—æœ€å¤§å›æ’¤"""
        if len(portfolio_values) < 2:
            return 0.0
            
        peak = portfolio_values[0]
        max_drawdown = 0.0
        
        for value in portfolio_values:
            if value > peak:
                peak = value
            drawdown = (peak - value) / peak
            if drawdown > max_drawdown:
                max_drawdown = drawdown
                
        return max_drawdown
    
    def generate_reports(self, results: List[Dict]):
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        logger.info("ğŸ“Š ç”ŸæˆæŠ•èµ„åˆ†ææŠ¥å‘Š...")
        
        # è®¡ç®—äº¤æ˜“æŒ‡æ ‡
        trading_metrics = self.calculate_trading_metrics(results)
        logger.info("ğŸ“ˆ äº¤æ˜“æŒ‡æ ‡è®¡ç®—å®Œæˆ")
        
        # ä¿å­˜è¯¦ç»†ç»“æœJSON
        results_file = self.run_dir / "results.json"
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        # ç”ŸæˆCSVæŠ¥å‘Š
        self._generate_csv_report(results)
        
        # ç”ŸæˆMarkdownæŠ¥å‘Š
        self._generate_markdown_report(results, trading_metrics)
        
        logger.info(f"âœ… æŠ¥å‘Šå·²ç”Ÿæˆåœ¨ {self.run_dir}")
    
    def _generate_csv_report(self, results: List[Dict]):
        """ç”ŸæˆCSVæ ¼å¼æŠ¥å‘Š"""
        import csv
        
        csv_file = self.run_dir / "trading_results.csv"
        
        with open(csv_file, 'w', newline='', encoding='utf-8') as f:
            if not results:
                return
                
            fieldnames = ['date', 'symbol', 'price', 'action', 'confidence', 'position', 'portfolio_value', 'daily_return']
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            
            for result in results:
                writer.writerow({
                    'date': result['date'],
                    'symbol': result['symbol'],
                    'price': result['price'],
                    'action': result['decision'].get('action', 'HOLD'),
                    'confidence': result['decision'].get('confidence', 0),
                    'position': result['position'],
                    'portfolio_value': result['portfolio_value'],
                    'daily_return': result['daily_return']
                })
    
    def _generate_markdown_report(self, results: List[Dict], trading_metrics: Dict[str, float]):
        """ç”ŸæˆMarkdownæ ¼å¼æŠ¥å‘Š"""
        if not results:
            return
            
        # è®¡ç®—ç»Ÿè®¡æ•°æ®
        total_days = len(results)
        actions = [r["decision"].get("action", "HOLD") for r in results]
        buy_count = actions.count("BUY")
        sell_count = actions.count("SELL")
        hold_count = actions.count("HOLD")
        
        initial_value = results[0]["portfolio_value"]
        final_value = results[-1]["portfolio_value"]
        total_return = (final_value / initial_value - 1) * 100
        
        avg_confidence = sum([r["decision"].get("confidence", 0) for r in results]) / total_days
        
        # ç”ŸæˆæŠ¥å‘Š
        report = f"""# INVESTOR-BENCH æŠ•èµ„å›æµ‹æŠ¥å‘Š

## ğŸ“Š åŸºæœ¬ä¿¡æ¯

| é¡¹ç›® | å€¼ |
|------|---|
| è‚¡ç¥¨ä»£ç  | {self.args.symbol} |
| åˆ†ææœŸé—´ | {results[0]['date']} è‡³ {results[-1]['date']} |
| æ€»äº¤æ˜“æ—¥ | {total_days} |
| è¿è¡Œæ¨¡å¼ | {self.args.mode} |
| ä½¿ç”¨æ¨¡å‹ | {self.args.model} |
| è¿è¡Œæ—¶é—´ | {self.start_time.strftime('%Y-%m-%d %H:%M:%S')} |

## ğŸ’° æŠ•èµ„è¡¨ç°

| æŒ‡æ ‡ | å€¼ |
|------|---|
| åˆå§‹èµ„é‡‘ | ${initial_value:,.2f} |
| æœ€ç»ˆä»·å€¼ | ${final_value:,.2f} |
| æ€»æ”¶ç›Šç‡ | {total_return:+.2f}% |
| å¹´åŒ–æ”¶ç›Šç‡ | {trading_metrics['annualized_return']*100:+.2f}% |
| å¹³å‡ç½®ä¿¡åº¦ | {avg_confidence:.2f} |

## ğŸ“Š é£é™©æŒ‡æ ‡

| æŒ‡æ ‡ | å€¼ |
|------|---|
| æ³¢åŠ¨ç‡ (å¹´åŒ–) | {trading_metrics['volatility']*100:.2f}% |
| å¤æ™®æ¯”ç‡ | {trading_metrics['sharpe_ratio']:.3f} |
| æœ€å¤§å›æ’¤ | {trading_metrics['max_drawdown']*100:.2f}% |
| èƒœç‡ | {trading_metrics['win_rate']*100:.1f}% |
| æ€»äº¤æ˜“æ¬¡æ•° | {trading_metrics['total_trades']} |

## ğŸ¯ å†³ç­–åˆ†å¸ƒ

| å†³ç­–ç±»å‹ | æ¬¡æ•° | å æ¯” |
|---------|------|------|
| BUY | {buy_count} | {buy_count/total_days*100:.1f}% |
| HOLD | {hold_count} | {hold_count/total_days*100:.1f}% |
| SELL | {sell_count} | {sell_count/total_days*100:.1f}% |

## ğŸ“ˆ è¯¦ç»†äº¤æ˜“è®°å½•

| æ—¥æœŸ | ä»·æ ¼ | å†³ç­– | ç½®ä¿¡åº¦ | ç»„åˆä»·å€¼ | æ—¥æ”¶ç›Šç‡ |
|------|------|------|--------|----------|----------|
"""
        
        for result in results:
            decision = result["decision"]
            report += f"| {result['date']} | ${result['price']:.2f} | {decision.get('action', 'HOLD')} | {decision.get('confidence', 0):.2f} | ${result['portfolio_value']:,.2f} | {result['daily_return']*100:+.2f}% |\\n"
        
        report += f"""
## ğŸ§  AIå†³ç­–æ´å¯Ÿ

### é«˜ç½®ä¿¡åº¦å†³ç­– (>0.8)
"""
        high_conf_decisions = [r for r in results if r["decision"].get("confidence", 0) > 0.8]
        for result in high_conf_decisions[:5]:  # æœ€å¤šæ˜¾ç¤º5ä¸ª
            decision = result["decision"]
            report += f"- **{result['date']}**: {decision.get('action')} (ç½®ä¿¡åº¦: {decision.get('confidence', 0):.2f})\\n"
            report += f"  ç†ç”±: {decision.get('reasoning', 'N/A')[:150]}...\\n\\n"
        
        report += f"""
## ğŸ”§ æŠ€æœ¯ä¿¡æ¯

### APIä½¿ç”¨ç»Ÿè®¡
- Chat APIè°ƒç”¨: {self.api_stats['chat_calls']}æ¬¡
- Embedding APIè°ƒç”¨: {self.api_stats['embedding_calls']}æ¬¡  
- æ€»Tokenæ¶ˆè€—: {self.api_stats['total_tokens']}
- APIé”™è¯¯æ¬¡æ•°: {self.api_stats['errors']}

### ç³»ç»Ÿé…ç½®
- OpenAI SDKç‰ˆæœ¬: {self.client._version if hasattr(self.client, '_version') else 'æœªçŸ¥'}
- API Base: {self.client.base_url}
- è¿è¡Œç›®å½•: {self.run_dir}

---
*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = self.run_dir / "analysis_report.md"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
    
    def save_metadata(self):
        """ä¿å­˜è¿è¡Œå…ƒæ•°æ®"""
        end_time = datetime.now()
        duration = (end_time - self.start_time).total_seconds()
        
        metadata = {
            "run_info": {
                "start_time": self.start_time.isoformat(),
                "end_time": end_time.isoformat(),
                "duration_seconds": duration,
                "run_directory": str(self.run_dir),
                "command_line": " ".join(sys.argv)
            },
            "configuration": {
                "symbol": self.args.symbol,
                "start_date": self.args.start_date,
                "end_date": self.args.end_date,
                "mode": self.args.mode,
                "model": self.args.model,
                "api_base": str(self.client.base_url) if self.client else None,
                "embedding_model": "Qwen/Qwen3-Embedding-4B"
            },
            "api_statistics": self.api_stats,
            "system_info": {
                "python_version": sys.version,
                "platform": sys.platform,
                "working_directory": os.getcwd()
            },
            "memory_records": len(self.memories),
            "version": "2.0.0"
        }
        
        metadata_file = self.run_dir / "metadata.json"
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ğŸ’¾ å…ƒæ•°æ®å·²ä¿å­˜: {metadata_file}")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="INVESTOR-BENCH - åŸºäºLLMçš„æ™ºèƒ½æŠ•èµ„å›æµ‹ç³»ç»Ÿ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  # ä½¿ç”¨ç¯å¢ƒå˜é‡ä¸­çš„APIé…ç½®
  python investor_bench.py --symbol JNJ --start-date 2020-07-02 --end-date 2020-07-10 --mode warmup
  
  # æŒ‡å®šç‰¹å®šçš„APIå‚æ•°
  python investor_bench.py --symbol AAPL --model gpt-4 --api-key sk-xxx --api-base https://api.openai.com/v1
  
  # ä½¿ç”¨æœ¬åœ°éƒ¨ç½²çš„æ¨¡å‹ï¼ˆé€šè¿‡OpenAI SDKï¼‰
  python investor_bench.py --symbol TSLA --model llama-3.1-8b --api-base http://localhost:8000/v1 --api-key fake
        """
    )
    
    # å¿…éœ€å‚æ•°
    parser.add_argument("--symbol", required=True, help="è‚¡ç¥¨ä»£ç  (å¦‚: JNJ, AAPL)")
    parser.add_argument("--start-date", required=True, help="å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)")
    parser.add_argument("--end-date", required=True, help="ç»“æŸæ—¥æœŸ (YYYY-MM-DD)")
    
    # å¯é€‰å‚æ•°
    parser.add_argument("--mode", default="backtest", choices=["warmup", "test", "backtest"], 
                        help="è¿è¡Œæ¨¡å¼ (é»˜è®¤: backtest)")
    parser.add_argument("--model", default="Qwen/Qwen3-8B", help="LLMæ¨¡å‹åç§°")
    parser.add_argument("--api-key", help="OpenAI APIå¯†é’¥ (æˆ–è®¾ç½®OPENAI_API_KEYç¯å¢ƒå˜é‡)")
    parser.add_argument("--api-base", help="APIåŸºç¡€URL (æˆ–è®¾ç½®OPENAI_API_BASEç¯å¢ƒå˜é‡)")
    parser.add_argument("--verbose", "-v", action="store_true", help="è¯¦ç»†è¾“å‡º")
    
    args = parser.parse_args()
    
    try:
        # åˆå§‹åŒ–ç³»ç»Ÿ
        system = InvestorBench(args)
        
        # è¿è¡Œå›æµ‹
        results = system.run_backtest()
        
        # ç”ŸæˆæŠ¥å‘Š
        system.generate_reports(results)
        
        # ä¿å­˜å…ƒæ•°æ®
        system.save_metadata()
        
        logger.info("ğŸ‰ å›æµ‹å®Œæˆï¼")
        logger.info(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {system.run_dir}")
        print(f"\\nâœ… å›æµ‹å®Œæˆï¼ç»“æœä¿å­˜åœ¨: {system.run_dir}")
        
    except Exception as e:
        logger.error(f"âŒ ç³»ç»Ÿé”™è¯¯: {e}")
        logger.error(traceback.format_exc())
        print(f"\\nâŒ è¿è¡Œå¤±è´¥: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()