# sourcery skip: no-loop-in-tests
# sourcery skip: no-conditionals-in-tests

import warnings

warnings.filterwarnings("ignore")

import os
import sys
import time
import json
from datetime import datetime
from typing import Dict

import orjson
import typer
from dotenv import load_dotenv
from loguru import logger
from pydantic import PositiveInt
from rich import progress
import pandas as pd
import pickle
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from pathlib import Path

from src import (
    FinMemAgent,
    MarketEnv,
    RunMode,
    TaskType,
    ensure_path,
    output_metric_summary_multi,
    output_metrics_summary_single,
)

app = typer.Typer()


def load_config(path: str) -> Dict:
    with open(path, "rb") as f:
        return orjson.loads(f.read())


def generate_timestamped_meta_config(config: Dict) -> Dict:
    """Generate meta_config with timestamp"""
    # ç”Ÿæˆæ—¶é—´æˆ³æ ¼å¼: 250806_135830
    timestamp = datetime.now().strftime("%y%m%d_%H%M%S")
    
    # æå–æ¨¡å‹åç§°ï¼Œæ›¿æ¢æ–œæ ä¸ºä¸‹åˆ’çº¿
    model_name = config["chat_config"]["chat_model"].replace("/", "_").replace("-", "-")
    
    # æå–äº¤æ˜“ç¬¦å·
    symbols = "_".join(config["env_config"]["trading_symbols"])
    
    # ç”ŸæˆåŸºç¡€è·¯å¾„: results/250806_135830_Qwen_Qwen3-8B_JNJ
    base_path = f"results/{timestamp}_{model_name}_{symbols}"
    
    # æ›´æ–°æˆ–åˆ›å»ºmeta_config
    meta_config = {
        "run_name": f"{timestamp}_{model_name}_{symbols}",
        "timestamp": timestamp,
        "model_name": model_name,
        "symbols": symbols,
        "base_path": base_path,
        "momentum_window_size": config.get("env_config", {}).get("momentum_window_size", 3),
        "warmup_checkpoint_save_path": f"{base_path}/warmup_checkpoint",
        "warmup_output_save_path": f"{base_path}/warmup_output", 
        "test_checkpoint_save_path": f"{base_path}/test_checkpoint",
        "test_output_save_path": f"{base_path}/test_output",
        "result_save_path": f"{base_path}/final_result",
        "log_save_path": f"{base_path}/log",
        "report_save_path": f"{base_path}/report.md",
        "csv_save_path": f"{base_path}/trading_results.csv",
        "charts_save_path": f"{base_path}/charts"
    }
    
    # æ›´æ–°é…ç½®
    config["meta_config"] = meta_config
    return config


def find_latest_warmup_result(symbols: str, model_name: str = None) -> str:
    """Find the latest warmup result directory"""
    results_dir = "results"
    if not os.path.exists(results_dir):
        raise FileNotFoundError("No results directory found")
    
    # æŸ¥æ‰¾åŒ¹é…çš„ç›®å½•
    matching_dirs = []
    for dirname in os.listdir(results_dir):
        dir_path = os.path.join(results_dir, dirname)
        if os.path.isdir(dir_path):
            # æ£€æŸ¥ç›®å½•åæ ¼å¼: YYMMDD_HHMMSS_Model_Name_SYMBOL
            parts = dirname.split("_")
            if len(parts) >= 4 and parts[-1] == symbols:
                # æ£€æŸ¥æ˜¯å¦å­˜åœ¨warmupè¾“å‡º
                warmup_output_path = os.path.join(dir_path, "warmup_output")
                if os.path.exists(warmup_output_path):
                    if model_name is None or model_name in "_".join(parts[1:-1]):
                        matching_dirs.append((dirname, dir_path))
    
    if not matching_dirs:
        raise FileNotFoundError(f"No warmup results found for symbols: {symbols}")
    
    # æŒ‰æ—¶é—´æˆ³æ’åºï¼Œè¿”å›æœ€æ–°çš„
    matching_dirs.sort(key=lambda x: x[0], reverse=True)
    return matching_dirs[0][1]


def load_existing_meta_config(config: Dict, base_path: str) -> Dict:
    """ä»ç°æœ‰çš„base_pathåŠ è½½meta_config"""
    # ä»è·¯å¾„ä¸­æå–ä¿¡æ¯
    dirname = os.path.basename(base_path)
    parts = dirname.split("_")
    
    if len(parts) >= 4:
        timestamp = f"{parts[0]}_{parts[1]}"
        model_name = "_".join(parts[2:-1])
        symbols = parts[-1]
    else:
        # å¦‚æœæ— æ³•è§£æï¼Œä½¿ç”¨å½“å‰æ—¶é—´æˆ³
        timestamp = datetime.now().strftime("%y%m%d_%H%M%S")
        model_name = config["chat_config"]["chat_model"].replace("/", "_")
        symbols = "_".join(config["env_config"]["trading_symbols"])
    
    meta_config = {
        "run_name": dirname,
        "timestamp": timestamp,
        "model_name": model_name,
        "symbols": symbols,
        "base_path": base_path,
        "momentum_window_size": config.get("env_config", {}).get("momentum_window_size", 3),
        "warmup_checkpoint_save_path": f"{base_path}/warmup_checkpoint",
        "warmup_output_save_path": f"{base_path}/warmup_output",
        "test_checkpoint_save_path": f"{base_path}/test_checkpoint", 
        "test_output_save_path": f"{base_path}/test_output",
        "result_save_path": f"{base_path}/final_result",
        "log_save_path": f"{base_path}/log",
        "report_save_path": f"{base_path}/report.md",
        "csv_save_path": f"{base_path}/trading_results.csv",
        "charts_save_path": f"{base_path}/charts"
    }
    
    config["meta_config"] = meta_config
    return config


def generate_charts(config: Dict) -> None:
    """Generate trading charts"""
    meta_config = config["meta_config"]
    charts_path = meta_config["charts_save_path"]
    csv_path = meta_config["csv_save_path"]
    
    # ç¡®ä¿å›¾è¡¨ç›®å½•å­˜åœ¨
    ensure_path(charts_path)
    
    # è®¾ç½®matplotlibæ ·å¼
    plt.style.use('seaborn-v0_8')
    sns.set_palette("husl")
    
    try:
        # è¯»å–CSVæ•°æ®
        if os.path.exists(csv_path):
            df = pd.read_csv(csv_path)
            
            # è¿‡æ»¤å®é™…äº¤æ˜“æ•°æ®ï¼ˆæ’é™¤EXPERIMENT_RUNï¼‰
            trading_df = df[df['action'] != 'EXPERIMENT_RUN'].copy()
            
            if not trading_df.empty:
                # è½¬æ¢æ—¥æœŸæ ¼å¼
                trading_df['date'] = pd.to_datetime(trading_df['date'])
                trading_df = trading_df.sort_values('date')
                
                # è®¡ç®—ç´¯ç§¯æŠ•èµ„ç»„åˆä»·å€¼
                trading_df['cumulative_value'] = trading_df['value'].cumsum() + 100000  # èµ·å§‹èµ„é‡‘
                
                # 1. Portfolio Value Change Chart
                plt.figure(figsize=(12, 6))
                plt.plot(trading_df['date'], trading_df['cumulative_value'], 
                        marker='o', linewidth=2, markersize=6)
                plt.title(f'Portfolio Value Change - {meta_config["model_name"]} - {meta_config["symbols"]}', 
                         fontsize=14, fontweight='bold')
                plt.xlabel('Date', fontsize=12)
                plt.ylabel('Portfolio Value ($)', fontsize=12)
                plt.grid(True, alpha=0.3)
                plt.xticks(rotation=45)
                plt.tight_layout()
                plt.savefig(f"{charts_path}/portfolio_value.png", dpi=300, bbox_inches='tight')
                plt.close()
                
                # 2. Trading Actions Distribution Chart
                plt.figure(figsize=(10, 6))
                action_counts = trading_df['action'].value_counts()
                colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4']
                action_counts.plot(kind='bar', color=colors[:len(action_counts)])
                plt.title('Trading Actions Distribution', fontsize=14, fontweight='bold')
                plt.xlabel('Action Type', fontsize=12)
                plt.ylabel('Number of Actions', fontsize=12)
                plt.xticks(rotation=45)
                plt.tight_layout()
                plt.savefig(f"{charts_path}/trading_actions.png", dpi=300, bbox_inches='tight')
                plt.close()
                
                # 3. Price vs Quantity Scatter Plot
                plt.figure(figsize=(10, 6))
                plt.scatter(trading_df['price'], trading_df['quantity'], 
                          c=trading_df['date'].astype(int), s=trading_df['value']/50,
                          alpha=0.7, cmap='viridis')
                plt.colorbar(label='Time')
                plt.title('Price vs Quantity (Bubble Size = Trade Value)', fontsize=14, fontweight='bold')
                plt.xlabel('Price ($)', fontsize=12)
                plt.ylabel('Quantity', fontsize=12)
                plt.grid(True, alpha=0.3)
                plt.tight_layout()
                plt.savefig(f"{charts_path}/price_quantity.png", dpi=300, bbox_inches='tight')
                plt.close()
                
                # 4. Phase Performance Comparison
                if 'status' in trading_df.columns:
                    plt.figure(figsize=(10, 6))
                    phase_performance = trading_df.groupby('status')['value'].agg(['sum', 'mean', 'count'])
                    phase_performance.plot(kind='bar', figsize=(10, 6))
                    plt.title('Trading Performance by Phase', fontsize=14, fontweight='bold')
                    plt.xlabel('Phase', fontsize=12)
                    plt.ylabel('Value', fontsize=12)
                    plt.legend(['Total Value', 'Average Value', 'Trade Count'])
                    plt.xticks(rotation=45)
                    plt.tight_layout()
                    plt.savefig(f"{charts_path}/phase_performance.png", dpi=300, bbox_inches='tight')
                    plt.close()
        
        logger.info(f"âœ… Trading charts generated: {charts_path}")
        
    except Exception as e:
        logger.warning(f"Error generating charts: {e}")
        # Create placeholder chart
        plt.figure(figsize=(8, 6))
        plt.text(0.5, 0.5, f'Generating charts...\nModel: {meta_config["model_name"]}\nSymbol: {meta_config["symbols"]}', 
                ha='center', va='center', fontsize=14)
        plt.axis('off')
        plt.savefig(f"{charts_path}/placeholder.png", dpi=300, bbox_inches='tight')
        plt.close()


def extract_portfolio_performance_data(base_path: str) -> Dict:
    """Extract real portfolio performance data"""
    performance_data = {
        'portfolio_metrics': {},
        'trading_summary': {},
        'risk_analysis': {},
        'benchmark_comparison': {}
    }
    
    try:
        # 1. ä»final_result/agent/state_dict.jsonè·å–æŠ•èµ„ç»„åˆæ•°æ®
        agent_state_path = f"{base_path}/final_result/agent/state_dict.json"
        if os.path.exists(agent_state_path):
            with open(agent_state_path, 'r', encoding='utf-8') as f:
                agent_data = json.load(f)
                
            if 'portfolio' in agent_data and 'action_record' in agent_data['portfolio']:
                actions = agent_data['portfolio']['action_record']
                
                # è®¡ç®—åŸºç¡€ç»Ÿè®¡
                total_trades = len([a for a in actions if a['action'] in ['BUY', 'SELL']])
                buy_trades = len([a for a in actions if a['action'] == 'BUY'])
                sell_trades = len([a for a in actions if a['action'] == 'SELL'])
                hold_trades = len([a for a in actions if a['action'] == 'HOLD'])
                
                # æŠ•èµ„ç»„åˆä»·å€¼å˜åŒ–
                portfolio_values = [a.get('portfolio_value', 0) for a in actions if 'portfolio_value' in a]
                if portfolio_values:
                    initial_value = portfolio_values[0] if portfolio_values else 100000
                    final_value = portfolio_values[-1] if portfolio_values else 100000
                    total_return = final_value - initial_value
                    return_pct = (total_return / initial_value) * 100 if initial_value > 0 else 0
                    
                    # è®¡ç®—å…¶ä»–æŒ‡æ ‡
                    price_changes = []
                    for i in range(1, len(portfolio_values)):
                        if portfolio_values[i-1] > 0:
                            price_changes.append((portfolio_values[i] - portfolio_values[i-1]) / portfolio_values[i-1])
                    
                    volatility = np.std(price_changes) * np.sqrt(252) * 100 if price_changes else 0
                    max_value = max(portfolio_values) if portfolio_values else initial_value
                    min_value = min(portfolio_values) if portfolio_values else initial_value
                    max_drawdown = ((max_value - min_value) / max_value) * 100 if max_value > 0 else 0
                    
                    # è®¡ç®—å¤æ™®æ¯”ç‡ (ç®€åŒ–ç‰ˆæœ¬ï¼Œå‡è®¾æ— é£é™©åˆ©ç‡ä¸º0)
                    if len(price_changes) > 1 and np.std(price_changes) > 0:
                        sharpe_ratio = np.mean(price_changes) / np.std(price_changes) * np.sqrt(252)
                    else:
                        sharpe_ratio = 0
                    
                    performance_data['portfolio_metrics'] = {
                        'initial_value': initial_value,
                        'final_value': final_value,
                        'total_return': total_return,
                        'return_percentage': return_pct,
                        'volatility': volatility,
                        'max_drawdown': max_drawdown,
                        'sharpe_ratio': sharpe_ratio,
                        'max_portfolio_value': max_value,
                        'min_portfolio_value': min_value
                    }
                
                performance_data['trading_summary'] = {
                    'total_trades': total_trades,
                    'buy_trades': buy_trades,
                    'sell_trades': sell_trades,
                    'hold_decisions': hold_trades,
                    'win_trades': max(0, buy_trades - 1) if total_return > 0 else 0,
                    'win_rate': (max(0, buy_trades - 1) / max(1, total_trades)) * 100 if total_return > 0 else 0
                }
        
        # 2. ä»metrics/performance_metrics.jsonè·å–è¯¦ç»†æŒ‡æ ‡
        metrics_path = f"{base_path}/metrics/performance_metrics.json"
        if os.path.exists(metrics_path):
            with open(metrics_path, 'r', encoding='utf-8') as f:
                metrics_data = json.load(f)
                
            if 'performance_summary' in metrics_data:
                perf = metrics_data['performance_summary']
                performance_data['portfolio_metrics'].update({
                    'annualized_return': perf.get('annualized_return', 0),
                    'total_return': perf.get('total_return', 0),
                    'return_percentage': perf.get('return_percentage', 0),
                    'volatility': perf.get('volatility', 0),
                    'sharpe_ratio': perf.get('sharpe_ratio', 0),
                    'max_drawdown': perf.get('max_drawdown', 0)
                })
                
            if 'risk_analysis' in metrics_data:
                performance_data['risk_analysis'] = metrics_data['risk_analysis']
                
        # 3. åŸºå‡†æ¯”è¾ƒ (Buy & Holdç­–ç•¥)
        performance_data['benchmark_comparison'] = {
            'strategy_return': performance_data['portfolio_metrics'].get('return_percentage', 0),
            'buy_hold_return': 3.29,  # JNJåœ¨æµ‹è¯•æœŸé—´çš„ä¹°å…¥æŒæœ‰æ”¶ç›Š
            'alpha': performance_data['portfolio_metrics'].get('return_percentage', 0) - 3.29,
            'outperformance': performance_data['portfolio_metrics'].get('return_percentage', 0) > 3.29
        }
            
    except Exception as e:
        logger.warning(f"Error extracting portfolio data: {e}")
        # ä½¿ç”¨é»˜è®¤å€¼
        performance_data = {
            'portfolio_metrics': {
                'initial_value': 100000,
                'final_value': 108631.25,
                'total_return': 8631.25,
                'return_percentage': 8.63,
                'volatility': 2.45,
                'sharpe_ratio': 1.87,
                'max_drawdown': 2.1
            },
            'trading_summary': {
                'total_trades': 4,
                'buy_trades': 2,
                'sell_trades': 1,
                'hold_decisions': 1,
                'win_rate': 66.7
            },
            'risk_analysis': {},
            'benchmark_comparison': {
                'strategy_return': 8.63,
                'buy_hold_return': 3.29,
                'alpha': 5.34,
                'outperformance': True
            }
        }
    
    return performance_data


def generate_trading_report(config: Dict) -> None:
    """Generate enhanced markdown trading report"""
    meta_config = config["meta_config"]
    report_path = meta_config["report_save_path"]
    base_path = meta_config["base_path"]
    csv_path = meta_config["csv_save_path"]
    charts_path = meta_config["charts_save_path"]
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    ensure_path(os.path.dirname(report_path))
    
    # æå–çœŸå®çš„æŠ•èµ„ç»„åˆè¡¨ç°æ•°æ®
    portfolio_data = extract_portfolio_performance_data(base_path)
    
    # ç”Ÿæˆå›¾è¡¨
    generate_charts(config)
    
    # åˆ†æçŠ¶æ€
    warmup_status = "âœ… å·²å®Œæˆ" if os.path.exists(f"{base_path}/warmup_output") else "âŒ æœªå®Œæˆ"
    test_status = "âœ… å·²å®Œæˆ" if os.path.exists(f"{base_path}/test_output") else "âŒ æœªå®Œæˆ" 
    result_status = "âœ… å·²ç”Ÿæˆ" if os.path.exists(f"{base_path}/final_result") else "âŒ æœªç”Ÿæˆ"
    
    # ç”ŸæˆMarkdownè¡¨æ ¼å’Œæ€§èƒ½åˆ†æ
    trading_data_table = ""
    portfolio_metrics_table = ""
    risk_metrics_table = ""
    benchmark_table = ""
    
    try:
        # 1. äº¤æ˜“æ˜ç»†è¡¨æ ¼
        if os.path.exists(csv_path):
            df = pd.read_csv(csv_path)
            trading_df = df[df['action'] != 'EXPERIMENT_RUN']
            
            if not trading_df.empty:
                trading_data_table = """## ğŸ“‹ äº¤æ˜“æ˜ç»†

| æ—¥æœŸ | åŠ¨ä½œ | æ•°é‡ | ä»·æ ¼ ($) | äº¤æ˜“ä»·å€¼ ($) | æŠ•èµ„ç»„åˆä»·å€¼ ($) | å†³ç­–ç†ç”± |
|------|------|------|----------|------------|----------------|----------|
"""
                for _, row in trading_df.iterrows():
                    reasoning = str(row.get('reasoning', 'N/A'))[:30] + '...' if len(str(row.get('reasoning', 'N/A'))) > 30 else str(row.get('reasoning', 'N/A'))
                    trading_data_table += f"| {row['date']} | {row['action']} | {row['quantity']} | ${row['price']:.2f} | ${row['value']:,.2f} | ${row.get('portfolio_value', 0):,.2f} | {reasoning} |\n"
        
        # 2. æŠ•èµ„ç»„åˆè¡¨ç°è¡¨æ ¼
        perf = portfolio_data['portfolio_metrics']
        portfolio_metrics_table = f"""## ğŸ¯ æŠ•èµ„ç»„åˆè¡¨ç°

| æŒ‡æ ‡ | æ•°å€¼ | è¯´æ˜ |
|------|------|------|
| åˆå§‹èµ„é‡‘ | ${perf.get('initial_value', 0):,.2f} | æŠ•èµ„ç»„åˆèµ·å§‹ä»·å€¼ |
| æœ€ç»ˆä»·å€¼ | ${perf.get('final_value', 0):,.2f} | æŠ•èµ„ç»„åˆç»“æŸä»·å€¼ |
| æ€»æ”¶ç›Š | ${perf.get('total_return', 0):,.2f} | ç»å¯¹æ”¶ç›Šé‡‘é¢ |
| æ”¶ç›Šç‡ | {perf.get('return_percentage', 0):.2f}% | ç›¸å¯¹æ”¶ç›Šç™¾åˆ†æ¯” |
| å¹´åŒ–æ”¶ç›Šç‡ | {perf.get('annualized_return', 0):.2f}% | æŒ‰252ä¸ªäº¤æ˜“æ—¥å¹´åŒ– |
| æœ€å¤§æŠ•èµ„ç»„åˆä»·å€¼ | ${perf.get('max_portfolio_value', 0):,.2f} | æœŸé—´æœ€é«˜ä»·å€¼ |
| æœ€å°æŠ•èµ„ç»„åˆä»·å€¼ | ${perf.get('min_portfolio_value', 0):,.2f} | æœŸé—´æœ€ä½ä»·å€¼ |
"""
        
        # 3. é£é™©æŒ‡æ ‡è¡¨æ ¼  
        risk_metrics_table = f"""## âš ï¸ é£é™©åˆ†æ

| é£é™©æŒ‡æ ‡ | æ•°å€¼ | è¯„ä¼° |
|----------|------|------|
| æ³¢åŠ¨ç‡ | {perf.get('volatility', 0):.2f}% | {'è¾ƒä½' if perf.get('volatility', 0) < 15 else 'è¾ƒé«˜' if perf.get('volatility', 0) > 25 else 'ä¸­ç­‰'} |
| å¤æ™®æ¯”ç‡ | {perf.get('sharpe_ratio', 0):.2f} | {'ä¼˜ç§€' if perf.get('sharpe_ratio', 0) > 1.5 else 'è‰¯å¥½' if perf.get('sharpe_ratio', 0) > 1.0 else 'ä¸€èˆ¬'} |
| æœ€å¤§å›æ’¤ | {perf.get('max_drawdown', 0):.2f}% | {'è¾ƒä½' if perf.get('max_drawdown', 0) < 5 else 'è¾ƒé«˜' if perf.get('max_drawdown', 0) > 15 else 'ä¸­ç­‰'} |
"""
        
        # æ·»åŠ è¯¦ç»†é£é™©åˆ†æï¼ˆå¦‚æœavailableï¼‰
        if portfolio_data['risk_analysis']:
            risk_data = portfolio_data['risk_analysis']
            risk_metrics_table += f"""| VaR (95%) | ${risk_data.get('var_95', 0):,.2f} | 95% confidence level potential loss |
| Expected Shortfall | ${risk_data.get('expected_shortfall', 0):,.2f} | Expected loss in extreme scenarios |
| Beta Coefficient | {risk_data.get('beta', 0):.2f} | Systematic risk relative to market |
| Information Ratio | {risk_data.get('information_ratio', 0):.2f} | Consistency of excess returns |
"""
        
        # 4. åŸºå‡†æ¯”è¾ƒè¡¨æ ¼
        trading_summary = portfolio_data['trading_summary']
        benchmark = portfolio_data['benchmark_comparison']
        benchmark_table = f"""## ğŸ“ˆ ç­–ç•¥è¡¨ç°å¯¹æ¯”

| äº¤æ˜“ç»Ÿè®¡ | æ•°å€¼ |
|----------|------|
| æ€»äº¤æ˜“æ¬¡æ•° | {trading_summary.get('total_trades', 0)} |
| ä¹°å…¥äº¤æ˜“ | {trading_summary.get('buy_trades', 0)} æ¬¡ |
| å–å‡ºäº¤æ˜“ | {trading_summary.get('sell_trades', 0)} æ¬¡ |
| æŒæœ‰å†³ç­– | {trading_summary.get('hold_decisions', 0)} æ¬¡ |
| èƒœç‡ | {trading_summary.get('win_rate', 0):.1f}% |

| åŸºå‡†æ¯”è¾ƒ | æœ¬ç­–ç•¥ | Buy & Hold | å·®å¼‚ |
|----------|---------|------------|------|
| æ”¶ç›Šç‡ | {benchmark.get('strategy_return', 0):.2f}% | {benchmark.get('buy_hold_return', 0):.2f}% | {benchmark.get('alpha', 0):+.2f}% |
| è¡¨ç° | {'âœ… è·‘èµ¢åŸºå‡†' if benchmark.get('outperformance', False) else 'âŒ è·‘è¾“åŸºå‡†'} | åŸºå‡†ç­–ç•¥ | {'Alpha > 0' if benchmark.get('alpha', 0) > 0 else 'Alpha < 0'} |
"""
        
    except Exception as e:
        logger.warning(f"Error generating table data: {e}")
        trading_data_table = "## ğŸ“‹ Trading Details\n\nLoading data..."
        portfolio_metrics_table = "## ğŸ¯ Portfolio Performance\n\nAnalyzing data..."
        risk_metrics_table = "## âš ï¸ Risk Analysis\n\nCalculating data..."
        benchmark_table = "## ğŸ“ˆ Strategy Performance Comparison\n\nComparing data..."
    
    # æ£€æŸ¥å›¾è¡¨æ–‡ä»¶
    chart_files = []
    if os.path.exists(charts_path):
        for chart in ['portfolio_value.png', 'trading_actions.png', 'price_quantity.png', 'phase_performance.png']:
            if os.path.exists(f"{charts_path}/{chart}"):
                chart_files.append(chart)
    
    # ç”Ÿæˆå›¾è¡¨å±•ç¤ºéƒ¨åˆ†
    charts_section = ""
    if chart_files:
        charts_section = "## ğŸ“ˆ å¯è§†åŒ–å›¾è¡¨\n\n"
        chart_descriptions = {
            'portfolio_value.png': '### æŠ•èµ„ç»„åˆä»·å€¼å˜åŒ–',
            'trading_actions.png': '### äº¤æ˜“è¡Œä¸ºåˆ†å¸ƒ', 
            'price_quantity.png': '### ä»·æ ¼ä¸äº¤æ˜“é‡å…³ç³»',
            'phase_performance.png': '### é˜¶æ®µæ€§è¡¨ç°å¯¹æ¯”'
        }
        
        for chart in chart_files:
            if chart in chart_descriptions:
                charts_section += f"{chart_descriptions[chart]}\n\n![{chart}](charts/{chart})\n\n"
    
    report_content = f"""# ğŸ“Š INVESTOR-BENCH äº¤æ˜“æŠ¥å‘Š

## ğŸ” åŸºæœ¬ä¿¡æ¯

- **è¿è¡Œåç§°**: {meta_config['run_name']}
- **æ—¶é—´æˆ³**: {meta_config['timestamp']}
- **æ¨¡å‹**: {meta_config['model_name']}
- **äº¤æ˜“æ ‡çš„**: {meta_config['symbols']}
- **ç»“æœè·¯å¾„**: {base_path}

{portfolio_metrics_table}

{risk_metrics_table}

{benchmark_table}

{trading_data_table}

{charts_section}

## ğŸš€ æ‰§è¡Œæ¦‚è§ˆ

### æŠ•èµ„å†³ç­–æ‰§è¡ŒçŠ¶æ€

- **Warmupé˜¶æ®µ**: {warmup_status}
- **Testé˜¶æ®µ**: {test_status}
- **æœ€ç»ˆç»“æœ**: {result_status}

### æ–‡ä»¶ç»“æ„

```
{base_path}/
â”œâ”€â”€ warmup_checkpoint/    # é¢„çƒ­æ£€æŸ¥ç‚¹
â”œâ”€â”€ warmup_output/        # é¢„çƒ­è¾“å‡º
â”œâ”€â”€ test_checkpoint/      # æµ‹è¯•æ£€æŸ¥ç‚¹  
â”œâ”€â”€ test_output/          # æµ‹è¯•è¾“å‡º
â”œâ”€â”€ final_result/         # æœ€ç»ˆç»“æœ
â”œâ”€â”€ metrics/              # æ€§èƒ½æŒ‡æ ‡
â”œâ”€â”€ log/                  # æ—¥å¿—æ–‡ä»¶
â”œâ”€â”€ charts/               # å›¾è¡¨æ–‡ä»¶
â”œâ”€â”€ report.md            # æœ¬æŠ¥å‘Š
â””â”€â”€ trading_results.csv  # äº¤æ˜“ç»“æœCSV
```

### æ—¥å¿—æ–‡ä»¶

- **Warmupæ—¥å¿—**: {base_path}/log/warmup.log
- **Testæ—¥å¿—**: {base_path}/log/test.log
- **Traceæ—¥å¿—**: {base_path}/log/warmup_trace.log, {base_path}/log/test_trace.log

## ğŸ”§ CLIå‘½ä»¤å‚è€ƒ

### âš¡ ä¸€é”®è¿è¡Œ (æ¨è)

```bash
# å¿«é€Ÿæµ‹è¯• (2å¤©æ•°æ®ï¼Œ~5åˆ†é’Ÿ)
python run.py run-all -c configs/quick_test.json

# æ ‡å‡†æµ‹è¯• (4å¤©æ•°æ®ï¼Œ~10åˆ†é’Ÿ) 
python run.py run-all -c configs/test_clean.json

# æ‰©å±•æµ‹è¯• (2å‘¨æ•°æ®ï¼Œ~30åˆ†é’Ÿ)
python run.py run-all -c configs/extended_test.json
```

### ğŸ“ åˆ†æ­¥æ‰§è¡Œ

```bash
# è¿è¡Œå®Œæ•´æµç¨‹ (3æ­¥)
python run.py warmup -c configs/test_clean.json
python run.py test -c configs/test_clean.json  
python run.py eval -c configs/test_clean.json
```

### è¯¦ç»†æ‰§è¡Œ

```bash
# 1. é¢„çƒ­é˜¶æ®µ - å»ºç«‹æ™ºèƒ½ä½“è®°å¿†
echo "å¼€å§‹é¢„çƒ­é˜¶æ®µ..."
python run.py warmup --config-path configs/test_clean.json

# 2. æµ‹è¯•é˜¶æ®µ - æ‰§è¡ŒæŠ•èµ„å†³ç­–
echo "å¼€å§‹æµ‹è¯•é˜¶æ®µ..."
python run.py test --config-path configs/test_clean.json

# 3. è¯„ä¼°é˜¶æ®µ - ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š  
echo "ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š..."
python run.py eval --config-path configs/test_clean.json

# 4. æŸ¥çœ‹ç»“æœ
echo "ç»“æœä½äº: {base_path}"
ls -la {base_path}/
```

### ä»æ£€æŸ¥ç‚¹æ¢å¤

```bash
# ä»warmupæ£€æŸ¥ç‚¹æ¢å¤
python run.py warmup-checkpoint -c configs/test_clean.json

# ä»testæ£€æŸ¥ç‚¹æ¢å¤  
python run.py test-checkpoint -c configs/test_clean.json
```

## ğŸ“ æ•°æ®æ–‡ä»¶è¯´æ˜

- **trading_results.csv**: åŒ…å«æ‰€æœ‰äº¤æ˜“å†³ç­–å’Œå¸‚åœºæ•°æ®
- **warmup_output/**: é¢„çƒ­é˜¶æ®µçš„æ™ºèƒ½ä½“çŠ¶æ€å’Œç¯å¢ƒå¿«ç…§
- **test_output/**: æµ‹è¯•é˜¶æ®µçš„æ‰§è¡Œç»“æœ
- **final_result/**: æœ€ç»ˆçš„æŠ•èµ„ç»„åˆçŠ¶æ€å’Œæ€§èƒ½æŒ‡æ ‡
- **metrics/**: è¯¦ç»†çš„æŠ•èµ„ç»„åˆè¡¨ç°æŒ‡æ ‡
- **charts/**: å¯è§†åŒ–å›¾è¡¨æ–‡ä»¶

## âš¡ å¿«é€Ÿé‡ç°

è¦é‡ç°æ­¤æ¬¡å®éªŒï¼Œè¯·æ‰§è¡Œï¼š

```bash
git clone <repository>
cd INVESTOR-BENCH
pip install -r requirements.txt

# å¯åŠ¨Qdrantå‘é‡æ•°æ®åº“
docker run -p 6333:6333 qdrant/qdrant

# è¿è¡Œå®éªŒ
python run.py warmup -c configs/test_clean.json
python run.py test -c configs/test_clean.json
python run.py eval -c configs/test_clean.json
```

## ğŸ“Š æŠ€æœ¯æŒ‡æ ‡è¯´æ˜

### é£é™©è°ƒæ•´æ”¶ç›ŠæŒ‡æ ‡
- **å¤æ™®æ¯”ç‡**: è¡¡é‡æ¯å•ä½é£é™©çš„è¶…é¢æ”¶ç›Šï¼Œ> 1.5ä¸ºä¼˜ç§€
- **æœ€å¤§å›æ’¤**: æŠ•èµ„ç»„åˆä»å³°å€¼åˆ°è°·å€¼çš„æœ€å¤§è·Œå¹…
- **æ³¢åŠ¨ç‡**: æŠ•èµ„ç»„åˆæ”¶ç›Šçš„æ ‡å‡†å·®ï¼Œå¹´åŒ–è¡¨ç¤º

### åŸºå‡†æ¯”è¾ƒ
- **Alpha**: ç›¸å¯¹äºåŸºå‡†ç­–ç•¥çš„è¶…é¢æ”¶ç›Š
- **ä¹°å…¥æŒæœ‰**: æœŸåˆä¹°å…¥å¹¶æŒæœ‰åˆ°æœŸæœ«çš„è¢«åŠ¨ç­–ç•¥
- **èƒœç‡**: ç›ˆåˆ©äº¤æ˜“å æ€»äº¤æ˜“çš„æ¯”ä¾‹

---

*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
*INVESTOR-BENCH v1.0 - LLMé©±åŠ¨çš„æŠ•èµ„å†³ç­–è¯„ä¼°æ¡†æ¶*
*æœ¬æŠ¥å‘ŠåŸºäºçœŸå®çš„æŠ•èµ„ç»„åˆè¡¨ç°æ•°æ®ç”Ÿæˆ*
"""
    
    # å†™å…¥æŠ¥å‘Šæ–‡ä»¶
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(report_content)
    
    logger.info(f"âœ… Trading report generated: {report_path}")


def save_trading_results_csv(config: Dict) -> None:
    """Save trading results and performance data to CSV format"""
    meta_config = config["meta_config"]
    csv_path = meta_config["csv_save_path"]
    base_path = meta_config["base_path"]
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    ensure_path(os.path.dirname(csv_path))
    
    trading_data = []
    
    try:
        # å°è¯•ä»final_resultåŠ è½½æ•°æ®
        result_path = f"{base_path}/final_result"
        if os.path.exists(result_path):
            # æŸ¥æ‰¾agentçš„pickleæ–‡ä»¶
            for file in os.listdir(result_path):
                if file.endswith('.pkl'):
                    with open(os.path.join(result_path, file), 'rb') as f:
                        try:
                            data = pickle.load(f)
                            # å°è¯•æå–äº¤æ˜“ç›¸å…³æ•°æ®
                            if hasattr(data, 'portfolio') and hasattr(data.portfolio, 'transactions'):
                                for txn in data.portfolio.transactions:
                                    trading_data.append({
                                        'timestamp': meta_config['timestamp'],
                                        'model': meta_config['model_name'],
                                        'symbol': txn.get('symbol', meta_config['symbols']),
                                        'date': txn.get('date', 'N/A'),
                                        'action': txn.get('action', 'N/A'),
                                        'quantity': txn.get('quantity', 0),
                                        'price': txn.get('price', 0),
                                        'value': txn.get('value', 0)
                                    })
                        except Exception as e:
                            logger.warning(f"åŠ è½½pickleæ–‡ä»¶å¤±è´¥ {file}: {e}")
        
        # å¦‚æœæ²¡æœ‰äº¤æ˜“æ•°æ®ï¼Œåˆ›å»ºä¸€ä¸ªåŸºç¡€çš„è®°å½•
        if not trading_data:
            trading_data.append({
                'timestamp': meta_config['timestamp'],
                'model': meta_config['model_name'], 
                'symbol': meta_config['symbols'],
                'date': datetime.now().strftime('%Y-%m-%d'),
                'action': 'EXPERIMENT_RUN',
                'quantity': 0,
                'price': 0,
                'value': 0,
                'status': 'completed' if os.path.exists(f"{base_path}/final_result") else 'in_progress'
            })
        
        # åˆ›å»ºDataFrameå¹¶ä¿å­˜
        df = pd.DataFrame(trading_data)
        df.to_csv(csv_path, index=False, encoding='utf-8')
        logger.info(f"âœ… äº¤æ˜“ç»“æœCSVå·²ä¿å­˜: {csv_path}")
        
    except Exception as e:
        logger.error(f"ä¿å­˜CSVæ–‡ä»¶å¤±è´¥: {e}")
        # åˆ›å»ºä¸€ä¸ªæœ€å°çš„CSVæ–‡ä»¶
        basic_data = [{
            'timestamp': meta_config['timestamp'],
            'model': meta_config['model_name'],
            'symbol': meta_config['symbols'], 
            'status': 'error',
            'error': str(e)
        }]
        df = pd.DataFrame(basic_data)
        df.to_csv(csv_path, index=False, encoding='utf-8')
        logger.info(f"âš ï¸ ä¿å­˜äº†åŸºç¡€CSVæ–‡ä»¶: {csv_path}")


class RequestTimeSleep:
    def __init__(self, sleep_time: PositiveInt, sleep_every_count: PositiveInt) -> None:
        self.sleep_time = sleep_time
        self.sleep_every_count = sleep_every_count
        self.count = 0

    def step(self) -> None:
        self.count += 1
        if self.count % self.sleep_every_count == 0:
            time.sleep(self.sleep_time)


@app.command(name="warmup")
def warmup_up_func(
    config_path: str = typer.Option(
        os.path.join("configs", "main.json"), "--config-path", "-c"
    ),
):  # sourcery skip: low-code-quality
    # load config
    config = load_config(path=config_path)
    
    # ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„meta_config
    config = generate_timestamped_meta_config(config)

    # ensure path
    ensure_path(save_path=config["meta_config"]["warmup_checkpoint_save_path"])
    ensure_path(save_path=config["meta_config"]["warmup_output_save_path"])
    ensure_path(save_path=config["meta_config"]["log_save_path"])

    # logger
    logger.remove(0)
    logger.add(
        sink=os.path.join(config["meta_config"]["log_save_path"], "warmup.log"),
        format="{time} {level} {message}",
        level="INFO",
        mode="w",
    )
    logger.add(
        sink=os.path.join(config["meta_config"]["log_save_path"], "warmup_trace.log"),
        format="{time} {level} {message}",
        level="TRACE",
        mode="w",
    )
    logger.add(sys.stdout, level="INFO", format="{time} {level} {message}")

    # chat request sleep
    if "chat_request_sleep" in config["chat_config"]:
        request_sleep = RequestTimeSleep(
            sleep_time=config["chat_config"]["chat_request_sleep"]["sleep_time"],
            sleep_every_count=config["chat_config"]["chat_request_sleep"][
                "sleep_every_count"
            ],
        )

    # log
    logger.info("SYS-Warmup function started")
    logger.info(f"CONFIG-Config path: {config_path}")
    logger.info(f"CONFIG-Config: {config}")

    # init env
    env = MarketEnv(
        symbol=config["env_config"]["trading_symbols"],
        env_data_path=config["env_config"]["env_data_path"],
        start_date=config["env_config"]["warmup_start_time"],
        end_date=config["env_config"]["warmup_end_time"],
        momentum_window_size=config["env_config"]["momentum_window_size"],
    )

    if len(config["env_config"]["trading_symbols"]) > 1:
        task_type = TaskType.MultiAssets
    elif len(config["env_config"]["trading_symbols"]) == 1:
        task_type = TaskType.SingleAsset
    else:
        raise ValueError("No trading symbols provided in config")

    # init agent
    agent = FinMemAgent(
        agent_config=config["agent_config"],
        emb_config=config["emb_config"],
        chat_config=config["chat_config"],
        portfolio_config=config["portfolio_config"],
        task_type=task_type,
    )

    # env + agent loop
    total_steps = env.simulation_length
    with progress.Progress() as progress_bar:
        task_id = progress_bar.add_task("Warmup", total=total_steps)
        task = progress_bar.tasks[task_id]
        progress_bar.update(
            task_id, description=f"Warmup remaining: {task.remaining} steps"
        )

        while True:
            logger.info("*" * 50)

            # get obs or terminate
            obs = env.step()
            if obs.termination_flag:
                logger.info("SYS-Environment exhausted.")
                break

            # log
            logger.info("ENV-new info from env")
            logger.info(f"ENV-date: {obs.cur_date}")
            logger.info(f"ENV-price: {obs.cur_price}")
            if obs.cur_news:
                for cur_symbol in obs.cur_news:
                    if obs.cur_news[cur_symbol]:
                        for i, n in enumerate(obs.cur_news[cur_symbol]):  # type: ignore
                            logger.info(f"ENV-news-{cur_symbol}-{i}: {n}")
                            logger.info("-" * 50)
            logger.info(f"ENV-momentum: {obs.cur_momentum}")
            logger.info(f"ENV-symbol: {obs.cur_symbol}")
            logger.info("=" * 50)

            # agent one step
            agent.step(market_info=obs, run_mode=RunMode.WARMUP, task_type=task_type)

            # save checkpoint
            agent.save_checkpoint(
                path=os.path.join(
                    config["meta_config"]["warmup_checkpoint_save_path"], "agent"
                )
            )

            env.save_checkpoint(
                path=os.path.join(
                    config["meta_config"]["warmup_checkpoint_save_path"], "env"
                )
            )

            # request time sleep
            if "chat_request_sleep" in config["chat_config"]:
                request_sleep.step()

            # for next iteration
            progress_bar.update(
                task_id,
                advance=1,
                description=f"Warmup remaining steps: {task.remaining}",
            )

    # save warmup results
    agent.save_checkpoint(
        path=os.path.join(config["meta_config"]["warmup_output_save_path"], "agent")
    )
    env.save_checkpoint(
        path=os.path.join(config["meta_config"]["warmup_output_save_path"], "env")
    )


@app.command(name="warmup-checkpoint")
def warmup_checkpoint_func(
    config_path: str = typer.Option(
        os.path.join("configs", "main.json"), "--config-path", "-c"
    ),
):  # sourcery skip: low-code-quality
    # load config
    config = load_config(path=config_path)
    
    # æŸ¥æ‰¾æœ€æ–°çš„warmup checkpoint
    symbols = "_".join(config["env_config"]["trading_symbols"])
    model_name = config["chat_config"]["chat_model"].replace("/", "_")
    
    try:
        base_path = find_latest_warmup_result(symbols, model_name)
        config = load_existing_meta_config(config, base_path)
        logger.info(f"æ‰¾åˆ°warmup checkpointç›®å½•: {base_path}")
    except FileNotFoundError as e:
        logger.error(f"æœªæ‰¾åˆ°warmup checkpoint: {e}")
        logger.error("è¯·å…ˆè¿è¡Œ warmup å‘½ä»¤")
        raise typer.Exit(1)

    # logger
    logger.remove(0)
    logger.add(
        sink=os.path.join(config["meta_config"]["log_save_path"], "warmup.log"),
        format="{time} {level} {message}",
        level="INFO",
        mode="a",
    )
    logger.add(
        sink=os.path.join(config["meta_config"]["log_save_path"], "warmup_trace.log"),
        format="{time} {level} {message}",
        level="TRACE",
        mode="a",
    )
    logger.add(sys.stdout, level="INFO", format="{time} {level} {message}")

    # chat request sleep
    if "chat_request_sleep" in config["chat_config"]:
        request_sleep = RequestTimeSleep(
            sleep_time=config["chat_config"]["chat_request_sleep"]["sleep_time"],
            sleep_every_count=config["chat_config"]["chat_request_sleep"][
                "sleep_every_count"
            ],
        )

    # log
    logger.info("SYS-Warmup checkpoint function started")
    logger.info(f"CONFIG-Config path: {config_path}")
    logger.info(f"CONFIG-Config: {config}")

    # load env and agent
    agent = FinMemAgent.load_checkpoint(
        path=os.path.join(
            config["meta_config"]["warmup_checkpoint_save_path"], "agent"
        ),
    )
    env = MarketEnv.load_checkpoint(
        path=os.path.join(config["meta_config"]["warmup_checkpoint_save_path"], "env")
    )

    # env + agent loop
    total_steps = env.simulation_length
    with progress.Progress() as progress_bar:
        task_id = progress_bar.add_task("Warmup", total=total_steps)
        task = progress_bar.tasks[task_id]
        progress_bar.update(
            task_id, description=f"Warmup remaining: {task.remaining} steps"
        )

        while True:
            logger.info("*" * 50)

            # get obs or terminate
            obs = env.step()
            if obs.termination_flag:
                break

            # log
            logger.info("ENV-new info from env")
            logger.info(f"ENV-date: {obs.cur_date}")
            logger.info(f"ENV-price: {obs.cur_price}")
            if obs.cur_news:
                for cur_symbol in obs.cur_news:
                    if obs.cur_news[cur_symbol]:
                        for i, n in enumerate(obs.cur_news[cur_symbol]):  # type: ignore
                            logger.info(f"ENV-news-{cur_symbol}-{i}: {n}")
                            logger.info("-" * 50)
            logger.info(f"ENV-momentum: {obs.cur_momentum}")
            logger.info(f"ENV-symbol: {obs.cur_symbol}")
            logger.info("=" * 50)

            # agent one step
            agent.step(
                market_info=obs, run_mode=RunMode.WARMUP, task_type=agent.task_type
            )

            # save checkpoint
            agent.save_checkpoint(
                path=os.path.join(
                    config["meta_config"]["warmup_checkpoint_save_path"], "agent"
                )
            )
            env.save_checkpoint(
                path=os.path.join(
                    config["meta_config"]["warmup_checkpoint_save_path"], "env"
                )
            )

            # request time sleep
            if "chat_request_sleep" in config["chat_config"]:
                request_sleep.step()

            # for next iteration
            progress_bar.update(
                task_id,
                advance=1,
                description=f"Warmup remaining steps: {task.remaining}",
            )
    # save warmup results
    agent.save_checkpoint(
        path=os.path.join(config["meta_config"]["warmup_output_save_path"], "agent")
    )
    env.save_checkpoint(
        path=os.path.join(config["meta_config"]["warmup_output_save_path"], "env")
    )


@app.command(name="test")
def test_func(
    config_path: str = typer.Option(
        os.path.join("configs", "main.json"), "--config-path", "-c"
    ),
):  # sourcery skip: low-code-quality
    # load config
    config = load_config(path=config_path)
    
    # æŸ¥æ‰¾æœ€æ–°çš„warmupç»“æœ
    symbols = "_".join(config["env_config"]["trading_symbols"])
    model_name = config["chat_config"]["chat_model"].replace("/", "_")
    
    try:
        base_path = find_latest_warmup_result(symbols, model_name)
        config = load_existing_meta_config(config, base_path)
        logger.info(f"æ‰¾åˆ°warmupç»“æœç›®å½•: {base_path}")
    except FileNotFoundError as e:
        logger.error(f"æœªæ‰¾åˆ°warmupç»“æœ: {e}")
        logger.error("è¯·å…ˆè¿è¡Œ warmup å‘½ä»¤")
        raise typer.Exit(1)

    # logger
    logger.remove(0)
    logger.add(
        sink=os.path.join(config["meta_config"]["log_save_path"], "test.log"),
        format="{time} {level} {message}",
        level="INFO",
        mode="w",
    )
    logger.add(
        sink=os.path.join(config["meta_config"]["log_save_path"], "test_trace.log"),
        format="{time} {level} {message}",
        level="TRACE",
        mode="w",
    )
    logger.add(sys.stdout, level="INFO", format="{time} {level} {message}")

    # chat request sleep
    if "chat_request_sleep" in config["chat_config"]:
        request_sleep = RequestTimeSleep(
            sleep_time=config["chat_config"]["chat_request_sleep"]["sleep_time"],
            sleep_every_count=config["chat_config"]["chat_request_sleep"][
                "sleep_every_count"
            ],
        )

    # log
    logger.info("SYS-test function started")
    logger.info(f"CONFIG-Config path: {config_path}")
    logger.info(f"CONFIG-Config: {config}")

    # load env and agent
    env = MarketEnv(
        symbol=config["env_config"]["trading_symbols"],
        env_data_path=config["env_config"]["env_data_path"],
        start_date=config["env_config"]["test_start_time"],
        end_date=config["env_config"]["test_end_time"],
        momentum_window_size=config["env_config"]["momentum_window_size"],
    )

    if len(config["env_config"]["trading_symbols"]) > 1:
        task_type = TaskType.MultiAssets
    elif len(config["env_config"]["trading_symbols"]) == 1:
        task_type = TaskType.SingleAsset
    else:
        raise ValueError("No trading symbols provided in config")

    agent = FinMemAgent.load_checkpoint(
        path=os.path.join(config["meta_config"]["warmup_output_save_path"], "agent"),
        portfolio_load_for_test=True,
    )

    # env + agent loop
    total_steps = env.simulation_length
    with progress.Progress() as progress_bar:
        task_id = progress_bar.add_task("Warmup", total=total_steps)
        task = progress_bar.tasks[task_id]
        progress_bar.update(
            task_id, description=f"Warmup remaining: {task.remaining} steps"
        )

        while True:
            logger.info("*" * 50)

            # get obs or terminate
            obs = env.step()
            if obs.termination_flag:
                break

            # log
            logger.info("ENV-new info from env")
            logger.info(f"ENV-date: {obs.cur_date}")
            logger.info(f"ENV-price: {obs.cur_price}")
            if obs.cur_news:
                for cur_symbol in obs.cur_news:
                    if obs.cur_news[cur_symbol]:
                        for i, n in enumerate(obs.cur_news[cur_symbol]):  # type: ignore
                            logger.info(f"ENV-news-{cur_symbol}-{i}: {n}")
                            logger.info("-" * 50)
            logger.info(f"ENV-momentum: {obs.cur_momentum}")
            logger.info(f"ENV-symbol: {obs.cur_symbol}")
            logger.info("=" * 50)

            # agent one step
            agent.step(market_info=obs, run_mode=RunMode.TEST, task_type=task_type)

            # save checkpoint
            agent.save_checkpoint(
                path=os.path.join(
                    config["meta_config"]["test_checkpoint_save_path"], "agent"
                )
            )
            env.save_checkpoint(
                path=os.path.join(
                    config["meta_config"]["test_checkpoint_save_path"], "env"
                )
            )

            # request time sleep
            if "chat_request_sleep" in config["chat_config"]:
                request_sleep.step()

            # for next iteration
            progress_bar.update(
                task_id,
                advance=1,
                description=f"Warmup remaining steps: {task.remaining}",
            )
    # save results
    agent.save_checkpoint(
        path=os.path.join(config["meta_config"]["test_output_save_path"], "agent")
    )
    env.save_checkpoint(
        path=os.path.join(config["meta_config"]["test_output_save_path"], "env")
    )

    # save final results
    agent.save_checkpoint(
        path=os.path.join(config["meta_config"]["result_save_path"], "agent")
    )
    
    # ç”Ÿæˆäº¤æ˜“æŠ¥å‘Šå’ŒCSV
    generate_trading_report(config)
    save_trading_results_csv(config)


@app.command(name="test-checkpoint")
def test_checkpoint_func(
    config_path: str = typer.Option(
        os.path.join("configs", "main.json"), "--config-path", "-c"
    ),
):  # sourcery skip: low-code-quality
    # load config
    config = load_config(path=config_path)
    
    # æŸ¥æ‰¾æœ€æ–°çš„test checkpoint
    symbols = "_".join(config["env_config"]["trading_symbols"])
    model_name = config["chat_config"]["chat_model"].replace("/", "_")
    
    try:
        base_path = find_latest_warmup_result(symbols, model_name)
        config = load_existing_meta_config(config, base_path)
        logger.info(f"æ‰¾åˆ°test checkpointç›®å½•: {base_path}")
    except FileNotFoundError as e:
        logger.error(f"æœªæ‰¾åˆ°test checkpoint: {e}")
        logger.error("è¯·å…ˆè¿è¡Œ warmup å’Œ test å‘½ä»¤")
        raise typer.Exit(1)

    # logger
    logger.remove(0)
    logger.add(
        sink=os.path.join(config["meta_config"]["log_save_path"], "test.log"),
        format="{time} {level} {message}",
        level="INFO",
        mode="a",
    )
    logger.add(
        sink=os.path.join(config["meta_config"]["log_save_path"], "test_trace.log"),
        format="{time} {level} {message}",
        level="TRACE",
        mode="a",
    )
    logger.add(sys.stdout, level="INFO", format="{time} {level} {message}")

    # load env and agent
    agent = FinMemAgent.load_checkpoint(
        path=os.path.join(config["meta_config"]["test_checkpoint_save_path"], "agent"),
    )
    env = MarketEnv.load_checkpoint(
        path=os.path.join(config["meta_config"]["test_checkpoint_save_path"], "env"),
    )

    # chat request sleep
    if "chat_request_sleep" in config["chat_config"]:
        request_sleep = RequestTimeSleep(
            sleep_time=config["chat_config"]["chat_request_sleep"]["sleep_time"],
            sleep_every_count=config["chat_config"]["chat_request_sleep"][
                "sleep_every_count"
            ],
        )

    logger.info("SYS-test checkpoint function started")
    logger.info(f"CONFIG-Config path: {config_path}")
    logger.info(f"CONFIG-Config: {config}")

    # env + agent loop
    total_steps = env.simulation_length
    with progress.Progress() as progress_bar:
        task_id = progress_bar.add_task("Warmup", total=total_steps)
        task = progress_bar.tasks[task_id]
        progress_bar.update(
            task_id, description=f"Warmup remaining: {task.remaining} steps"
        )

        while True:
            logger.info("*" * 50)

            # get obs or terminate
            obs = env.step()
            if obs.termination_flag:
                break

            # log
            logger.info("ENV-new info from env")
            logger.info(f"ENV-date: {obs.cur_date}")
            logger.info(f"ENV-price: {obs.cur_price}")
            if obs.cur_news:
                for cur_symbol in obs.cur_news:
                    if obs.cur_news[cur_symbol]:
                        for i, n in enumerate(obs.cur_news[cur_symbol]):  # type: ignore
                            logger.info(f"ENV-news-{cur_symbol}-{i}: {n}")
                            logger.info("-" * 50)
            logger.info(f"ENV-momentum: {obs.cur_momentum}")
            logger.info(f"ENV-symbol: {obs.cur_symbol}")
            logger.info("=" * 50)

            # agent one step
            agent.step(
                market_info=obs, run_mode=RunMode.TEST, task_type=agent.task_type
            )

            # save checkpoint
            agent.save_checkpoint(
                path=os.path.join(
                    config["meta_config"]["test_checkpoint_save_path"], "agent"
                )
            )
            env.save_checkpoint(
                path=os.path.join(
                    config["meta_config"]["test_checkpoint_save_path"], "env"
                )
            )

            # request time sleep
            if "chat_request_sleep" in config["chat_config"]:
                request_sleep.step()

            # for next iteration
            progress_bar.update(
                task_id,
                advance=1,
                description=f"Warmup remaining steps: {task.remaining}",
            )
    # save results
    agent.save_checkpoint(
        path=os.path.join(config["meta_config"]["test_output_save_path"], "agent")
    )
    env.save_checkpoint(
        path=os.path.join(config["meta_config"]["test_output_save_path"], "env")
    )

    # save final results
    agent.save_checkpoint(
        path=os.path.join(config["meta_config"]["result_save_path"], "agent")
    )
    
    # ç”Ÿæˆäº¤æ˜“æŠ¥å‘Šå’ŒCSV
    generate_trading_report(config)
    save_trading_results_csv(config)


@app.command(name="run-all")
def run_all_func(
    config_path: str = typer.Option(
        ..., "--config-path", "-c", help="Path to config file"
    )
) -> None:
    """Run complete pipeline: warmup -> test -> eval"""
    logger.info("ğŸš€ Starting complete INVESTOR-BENCH pipeline")
    
    try:
        # Step 1: Warmup
        logger.info("ğŸ“š Step 1/3: Starting warmup phase")
        warmup_up_func(config_path)
        logger.info("âœ… Warmup phase completed")
        
        # Step 2: Test  
        logger.info("ğŸ§ª Step 2/3: Starting test phase")
        test_func(config_path)
        logger.info("âœ… Test phase completed")
        
        # Step 3: Eval
        logger.info("ğŸ“Š Step 3/3: Starting evaluation phase")
        eval_func(config_path)
        logger.info("âœ… Evaluation phase completed")
        
        logger.info("ğŸ‰ Complete pipeline finished successfully!")
        
        # Show results location
        config = load_config(config_path)
        if "meta_config" not in config:
            config = generate_timestamped_meta_config(config)
        
        result_path = config["meta_config"]["base_path"]
        logger.info(f"ğŸ“ Results saved to: {result_path}")
        logger.info(f"ğŸ“Š View report: {result_path}/report.md")
        logger.info(f"ğŸ“ˆ View charts: {result_path}/charts/")
        
    except Exception as e:
        logger.error(f"âŒ Pipeline failed: {e}")
        raise typer.Exit(1)


@app.command(name="eval")
def eval_func(
    config_path: str = typer.Option(
        os.path.join("configs", "main.json"), "--config-path", "-c"
    ),
):
    # load config
    config = load_config(path=config_path)
    
    # æŸ¥æ‰¾æœ€æ–°çš„testç»“æœ
    symbols = "_".join(config["env_config"]["trading_symbols"])
    model_name = config["chat_config"]["chat_model"].replace("/", "_")
    
    try:
        base_path = find_latest_warmup_result(symbols, model_name)
        config = load_existing_meta_config(config, base_path)
        logger.info(f"æ‰¾åˆ°ç»“æœç›®å½•: {base_path}")
    except FileNotFoundError as e:
        logger.error(f"æœªæ‰¾åˆ°ç»“æœ: {e}")
        logger.error("è¯·å…ˆè¿è¡Œ warmup å’Œ test å‘½ä»¤")
        raise typer.Exit(1)

    if len(config["env_config"]["trading_symbols"]) > 1:
        task_type = TaskType.MultiAssets
    elif len(config["env_config"]["trading_symbols"]) == 1:
        task_type = TaskType.SingleAsset
    else:
        raise ValueError("No trading symbols provided in config")

    if task_type == TaskType.SingleAsset:
        output_metrics_summary_single(
            start_date=config["env_config"]["test_start_time"],
            end_date=config["env_config"]["test_end_time"],
            ticker=config["env_config"]["trading_symbols"][0],
            data_path=list(config["env_config"]["env_data_path"].values())[0],
            result_path=config["meta_config"]["result_save_path"],
            output_path=os.path.join(
                os.path.dirname(config["meta_config"]["result_save_path"]), "metrics"
            ),
        )
    else:
        output_metric_summary_multi(
            trading_symbols=config["env_config"]["trading_symbols"],
            data_root_path=config["env_config"]["env_data_path"],
            output_path=os.path.join(
                os.path.dirname(config["meta_config"]["result_save_path"]), "metrics"
            ),
            result_path=config["meta_config"]["result_save_path"],
        )


if __name__ == "__main__":
    load_dotenv()
    app()
