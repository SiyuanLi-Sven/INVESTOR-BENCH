# é…ç½®ç®¡ç†

INVESTOR-BENCHä½¿ç”¨PKLé…ç½®è¯­è¨€å®ç°ç±»å‹å®‰å…¨çš„é…ç½®ç®¡ç†ï¼Œæœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»é…ç½®ç³»ç»Ÿçš„ä½¿ç”¨æ–¹æ³•ã€‚

## ğŸ—ï¸ é…ç½®æ¶æ„

### é…ç½®æ–‡ä»¶å±‚çº§

```
configs/
â”œâ”€â”€ main.pkl              # ä¸»é…ç½®å…¥å£
â”œâ”€â”€ meta.pkl              # ç±»å‹å®šä¹‰å’Œçº¦æŸ
â”œâ”€â”€ chat_models.pkl       # LLMæ¨¡å‹é…ç½®
â”œâ”€â”€ embedding.pkl         # Embeddingæ¨¡å‹é…ç½®
â”œâ”€â”€ data.pkl              # æ•°æ®è·¯å¾„é…ç½®
â”œâ”€â”€ memory.pkl            # è®°å¿†ç³»ç»Ÿå‚æ•°
â”œâ”€â”€ character_string_catalog.pkl  # è§’è‰²è®¾å®š
â””â”€â”€ main.json             # ç”Ÿæˆçš„JSONé…ç½® (è‡ªåŠ¨ç”Ÿæˆ)
```

### é…ç½®ç”Ÿæˆæµç¨‹

```mermaid
graph LR
    A[PKLæºæ–‡ä»¶] --> B[PKLç¼–è¯‘å™¨]
    B --> C[ç±»å‹æ£€æŸ¥]
    C --> D[JSONç”Ÿæˆ]
    D --> E[Pythonç¨‹åºè¯»å–]
    
    F[meta.pkl] --> B
    G[chat_models.pkl] --> B
    H[embedding.pkl] --> B
    I[main.pkl] --> B
```

## ğŸ“ æ ¸å¿ƒé…ç½®æ–‡ä»¶è¯¦è§£

### 1. main.pkl - ä¸»é…ç½®

**ç”¨é€”**: é…ç½®å…¥å£ï¼Œç»„è£…æ‰€æœ‰é…ç½®æ¨¡å—

```pkl
import "meta.pkl"
import "data.pkl" 
import "memory.pkl"
import "chat_models.pkl"
import "embedding.pkl"
import "character_string_catalog.pkl"

// ä¸»é…ç½®å®šä¹‰
hidden config = new meta.MetaConfig {
    run_name = "exp"                              // å®éªŒåç§°
    agent_name = "agent"                          // ä»£ç†åç§°
    
    // äº¤æ˜“æ ‡çš„é…ç½®
    trading_symbols = new Listing {
        "JNJ"                                     // å¼ºç”Ÿå…¬å¸
    }
    
    // æ—¶é—´èŒƒå›´é…ç½®
    warmup_start_time = "2020-07-02"              // å­¦ä¹ å¼€å§‹æ—¶é—´
    warmup_end_time = "2020-07-10"                // å­¦ä¹ ç»“æŸæ—¶é—´  
    test_start_time = "2020-10-01"                // æµ‹è¯•å¼€å§‹æ—¶é—´
    test_end_time = "2021-05-06"                  // æµ‹è¯•ç»“æŸæ—¶é—´
    
    // ç³»ç»Ÿå‚æ•°
    top_k = 5                                     // è®°å¿†æ£€ç´¢æ•°é‡
    look_back_window_size = 3                     // å›çœ‹çª—å£å¤§å°
    momentum_window_size = 3                      // åŠ¨é‡çª—å£å¤§å°
    
    // æ¨¡å‹é…ç½®
    embedding_model = "qwen3-embedding-4b-siliconflow"
    chat_model = "qwen3-8b-siliconflow"
    
    // APIå‚æ•°
    chat_vllm_endpoint = "http://0.0.0.0:8000"   // VLLMç«¯ç‚¹ (å¯é€‰)
    chat_parameters = new Mapping {
        ["temperature"] = 0.6                     // LLMæ¸©åº¦å‚æ•°
    }
}

// ç”Ÿæˆå„æ¨¡å—é…ç½®
chat_config = // ... èŠå¤©é…ç½®ç»„è£…é€»è¾‘
emb_config = // ... åµŒå…¥é…ç½®ç»„è£…é€»è¾‘  
env_config = // ... ç¯å¢ƒé…ç½®ç»„è£…é€»è¾‘
portfolio_config = // ... ç»„åˆé…ç½®ç»„è£…é€»è¾‘
agent_config = // ... ä»£ç†é…ç½®ç»„è£…é€»è¾‘
meta_config = // ... å…ƒé…ç½®ç»„è£…é€»è¾‘
```

### 2. meta.pkl - ç±»å‹å®šä¹‰

**ç”¨é€”**: å®šä¹‰é…ç½®ç»“æ„å’Œç±»å‹çº¦æŸ

```pkl
import "chat_models.pkl"
import "character_string_catalog.pkl"

// ä¸»é…ç½®ç±»å‹å®šä¹‰
class MetaConfig {
    run_name: String                              // å®éªŒåç§°
    agent_name: String                            // ä»£ç†åç§°
    
    // äº¤æ˜“æ ‡çš„ (å¿…é¡»åœ¨character_string_dictä¸­å­˜åœ¨)
    trading_symbols: Listing<String(character_string_catalog.character_string_dict.toMap().keys.contains(this))>
    
    // æ—¶é—´é…ç½® (ISOæ—¥æœŸæ ¼å¼)
    warmup_start_time: String
    warmup_end_time: String
    test_start_time: String
    test_end_time: String
    
    // æ•°å€¼å‚æ•° (å¸¦çº¦æŸ)
    top_k: Int(this >= 1)
    look_back_window_size: Int(this >= 1)
    momentum_window_size: Int(this >= 1)
    
    // æ¨¡å‹é…ç½® (å¿…é¡»åœ¨é¢„å®šä¹‰åˆ—è¡¨ä¸­)
    embedding_model: String(this is "text-embedding-3-large"|"text-embedding-3-small"|"text-embedding-ada-002"|"qwen3-embedding-4b-siliconflow")
    chat_model: String(chat_models.chat_model_dict.toMap().keys.contains(this))
    
    // å¯é€‰å‚æ•° (å¸¦é»˜è®¤å€¼)
    embedding_timeout: Int(this >= 100) = 600
    chat_request_timeout: Int(this >= 1000) = 1000
    chat_max_new_token: Int(this >= 3) = 1000
    chat_vllm_endpoint: String | Null = null
    chat_parameters: Mapping
    
    // è®°å¿†æ•°æ®åº“é…ç½®
    memory_db_endpoint: String = "http://localhost:6333"
    memory_importance_upper_bound: Float(this > 0) = 100.0
    memory_importance_score_update_step: Float(this > 0) = 18.0
}
```

### 3. chat_models.pkl - LLMæ¨¡å‹é…ç½®

**ç”¨é€”**: å®šä¹‰æ‰€æœ‰æ”¯æŒçš„LLMæ¨¡å‹

```pkl
// æ¨¡å‹é…ç½®åŸºç±»
class ChatModelConfig {
    chat_model: String                            // æ¨¡å‹åç§°
    lora: Boolean = false                         // æ˜¯å¦ä½¿ç”¨LoRA
    lora_path: String| Null = null                // LoRAè·¯å¾„
    lora_base_model: String|Null = null           // LoRAåŸºç¡€æ¨¡å‹
    chat_model_type: Null|String                  // æ¨¡å‹ç±»å‹: "completion"|"instruction"|"chat"
    chat_model_inference_engine: String           // æ¨ç†å¼•æ“: "vllm"|"openai"|"anthropic"
    chat_system_message: Null|String = null      // ç³»ç»Ÿæ¶ˆæ¯
    chat_endpoint: Null|String                    // APIç«¯ç‚¹
    chat_template_path: Null|String               // èŠå¤©æ¨¡æ¿è·¯å¾„
    chat_parameters: Mapping                      // æ¨¡å‹å‚æ•°
    chat_request_sleep: Mapping|Null = null      // è¯·æ±‚æ§åˆ¶
}

// SiliconFlow APIé…ç½®ç¤ºä¾‹
qwen3_8b_siliconflow: ChatModelConfig = new {
    chat_model = "Qwen/Qwen3-8B"
    chat_model_type = "chat"
    chat_model_inference_engine = "openai"
    chat_endpoint = "https://api.siliconflow.cn/v1/chat/completions"
    chat_template_path = null
    chat_system_message = "You are a helpful assistant."
    chat_parameters = new Mapping {
        ["temperature"] = 0.7
        ["max_tokens"] = 1024
    }
    chat_request_sleep = new Mapping {
        ["sleep_time"] = 2
        ["sleep_every_count"] = 10
    }
}

// æ¨¡å‹æ³¨å†Œè¡¨
chat_model_dict = new Mapping {
    ["qwen3-8b-siliconflow"] = qwen3_8b_siliconflow
    ["gpt-4o"] = gpt_4o
    ["claude-sonnet-35"] = claude_sonnet_35
    // ... æ›´å¤šæ¨¡å‹
}
```

### 4. embedding.pkl - Embeddingé…ç½®

```pkl
// Embeddingé…ç½®åŸºç±»
class EmbEndpointConfig {
    emb_model_name: String                        // æ¨¡å‹åç§°
    request_endpoint: String                      // APIç«¯ç‚¹
    emb_size: Int(this > 0)                      // å‘é‡ç»´åº¦
}

// SiliconFlow Embeddingé…ç½®
qwen3_embedding_4b_siliconflow: EmbEndpointConfig = new {
    emb_model_name = "Qwen/Qwen3-Embedding-4B"
    request_endpoint = "https://api.siliconflow.cn/v1/embeddings"
    emb_size = 2560
}

// Embeddingæ¨¡å‹æ³¨å†Œè¡¨
embedding_models = new Mapping {
    ["qwen3-embedding-4b-siliconflow"] = qwen3_embedding_4b_siliconflow
    ["text-embedding-3-large"] = text_embedding_3_large
    // ... æ›´å¤šæ¨¡å‹
}
```

## ğŸ› ï¸ é…ç½®æ“ä½œæŒ‡å—

### ç”Ÿæˆé…ç½®æ–‡ä»¶

```bash
# åŸºæœ¬ç”Ÿæˆ
pkl eval -f json -o configs/main.json configs/main.pkl

# éªŒè¯è¯­æ³•
pkl eval configs/main.pkl > /dev/null

# æŸ¥çœ‹ç‰¹å®šé…ç½®æ®µ
pkl eval -p chat_config configs/main.pkl
pkl eval -p emb_config configs/main.pkl
```

### åŠ¨æ€ä¿®æ”¹é…ç½®

```bash
# ä¿®æ”¹æ¨¡å‹é…ç½®
pkl eval -e 'configs/main.pkl.amend { 
    chat_model = "gpt-4o" 
}' -f json -o configs/main.json

# ä¿®æ”¹äº¤æ˜“æ ‡çš„
pkl eval -e 'configs/main.pkl.amend { 
    trading_symbols = new Listing { "AAPL", "GOOGL" } 
}' -f json -o configs/main.json

# ä¿®æ”¹æ—¶é—´èŒƒå›´
pkl eval -e 'configs/main.pkl.amend { 
    test_start_time = "2021-01-01",
    test_end_time = "2021-12-31"
}' -f json -o configs/main.json
```

### é…ç½®éªŒè¯

```bash
# ç±»å‹æ£€æŸ¥
pkl eval -m configs/meta.pkl configs/main.pkl

# çº¦æŸæ£€æŸ¥
pkl eval configs/main.pkl | jq '.chat_config.chat_model'
pkl eval configs/main.pkl | jq '.env_config.trading_symbols'
```

## ğŸ¯ å¸¸è§é…ç½®åœºæ™¯

### 1. æ·»åŠ æ–°çš„LLMæ¨¡å‹

**æ­¥éª¤1**: åœ¨`chat_models.pkl`ä¸­æ·»åŠ æ¨¡å‹é…ç½®
```pkl
your_model: ChatModelConfig = new {
    chat_model = "your-org/your-model"
    chat_model_type = "chat"
    chat_model_inference_engine = "openai"  // æˆ– "anthropic"
    chat_endpoint = "https://your-api-endpoint.com/v1/chat/completions"
    chat_system_message = "You are a helpful assistant."
    chat_parameters = new Mapping {
        ["temperature"] = 0.7
        ["max_tokens"] = 1024
    }
}
```

**æ­¥éª¤2**: æ·»åŠ åˆ°æ¨¡å‹æ³¨å†Œè¡¨
```pkl
chat_model_dict = new Mapping {
    // ... ç°æœ‰æ¨¡å‹
    ["your-model"] = your_model
}
```

**æ­¥éª¤3**: åœ¨ä¸»é…ç½®ä¸­ä½¿ç”¨
```pkl
chat_model = "your-model"
```

### 2. é…ç½®å¤šèµ„äº§ç»„åˆ

```pkl
trading_symbols = new Listing {
    "AAPL"   // è‹¹æœ
    "GOOGL"  // è°·æ­Œ
    "MSFT"   // å¾®è½¯
    "AMZN"   // äºšé©¬é€Š
}
```

**æ³¨æ„**: ç¡®ä¿æ¯ä¸ªsymboléƒ½æœ‰å¯¹åº”çš„æ•°æ®æ–‡ä»¶å’Œè§’è‰²è®¾å®šã€‚

### 3. è°ƒæ•´è®°å¿†ç³»ç»Ÿå‚æ•°

```pkl
// åœ¨memory.pklä¸­ä¿®æ”¹
short_config = new {
    importance_init_val = 40.0        // é™ä½åˆå§‹é‡è¦æ€§
    decay_recency_factor = 2.0        // æ›´å¿«è¡°å‡
    jump_upper_threshold = 60.0       // æé«˜æ™‹å‡é˜ˆå€¼
}
```

### 4. ä¼˜åŒ–APIè°ƒç”¨å‚æ•°

```pkl
// å‡å°‘APIè°ƒç”¨é¢‘ç‡
chat_request_sleep = new Mapping {
    ["sleep_time"] = 5                // å¢åŠ å»¶è¿Ÿ
    ["sleep_every_count"] = 3         // å‡å°‘æ‰¹æ¬¡å¤§å°
}

// è°ƒæ•´LLMå‚æ•°
chat_parameters = new Mapping {
    ["temperature"] = 0.3             // é™ä½éšæœºæ€§
    ["max_tokens"] = 512              // å‡å°‘tokenæ•°é‡
    ["top_p"] = 0.8                   // æ·»åŠ top-pé‡‡æ ·
}
```

## ğŸ”§ é«˜çº§é…ç½®æŠ€å·§

### 1. æ¡ä»¶é…ç½®

```pkl
// æ ¹æ®ç¯å¢ƒé€‰æ‹©é…ç½®
chat_endpoint = if (env.ENVIRONMENT == "production") 
    "https://api.production.com/v1/chat/completions"
else 
    "https://api.staging.com/v1/chat/completions"
```

### 2. é…ç½®ç»§æ‰¿

```pkl
// åŸºç¡€æ¨¡å‹é…ç½®
base_openai: ChatModelConfig = new {
    chat_model_type = "chat"
    chat_model_inference_engine = "openai"
    chat_system_message = "You are a helpful assistant."
    chat_parameters = new Mapping {
        ["temperature"] = 0.7
    }
}

// ç»§æ‰¿å¹¶æ‰©å±•
gpt4_custom: ChatModelConfig = (base_openai) {
    chat_model = "gpt-4"
    chat_endpoint = "https://api.openai.com/v1/chat/completions"
    chat_parameters = (base_openai.chat_parameters) {
        ["max_tokens"] = 2048
    }
}
```

### 3. é…ç½®æ¨¡æ¿

```pkl
// åˆ›å»ºé…ç½®æ¨¡æ¿å‡½æ•°
function createOpenAIConfig(model: String, endpoint: String) = new ChatModelConfig {
    chat_model = model
    chat_model_type = "chat" 
    chat_model_inference_engine = "openai"
    chat_endpoint = endpoint
    chat_system_message = "You are a helpful assistant."
    chat_parameters = new Mapping {
        ["temperature"] = 0.7
        ["max_tokens"] = 1024
    }
}

// ä½¿ç”¨æ¨¡æ¿
gpt4o: ChatModelConfig = createOpenAIConfig("gpt-4o", "https://api.openai.com/v1/chat/completions")
```

## ğŸš¨ é…ç½®æœ€ä½³å®è·µ

### 1. ç‰ˆæœ¬æ§åˆ¶
- æ‰€æœ‰PKLæºæ–‡ä»¶çº³å…¥ç‰ˆæœ¬æ§åˆ¶
- JSONæ–‡ä»¶å¯ä»¥å¿½ç•¥ï¼ˆè‡ªåŠ¨ç”Ÿæˆï¼‰
- ä½¿ç”¨æœ‰æ„ä¹‰çš„é…ç½®æ–‡ä»¶åå’Œæ³¨é‡Š

### 2. ç¯å¢ƒåˆ†ç¦»
```pkl
// å¼€å‘ç¯å¢ƒ
dev_config = new MetaConfig {
    run_name = "dev"
    warmup_end_time = "2020-07-10"    // çŸ­æœŸæµ‹è¯•
    chat_parameters = new Mapping {
        ["temperature"] = 1.0         // é«˜éšæœºæ€§ä¾¿äºè°ƒè¯•
    }
}

// ç”Ÿäº§ç¯å¢ƒ
prod_config = new MetaConfig {
    run_name = "prod"
    warmup_end_time = "2020-09-30"    // å®Œæ•´è®­ç»ƒ
    chat_parameters = new Mapping {
        ["temperature"] = 0.6         // ç¨³å®šçš„è¾“å‡º
    }
}
```

### 3. é…ç½®éªŒè¯
- ä½¿ç”¨ç±»å‹çº¦æŸé˜²æ­¢é…ç½®é”™è¯¯
- æ·»åŠ èŒƒå›´æ£€æŸ¥ç¡®ä¿å‚æ•°åˆç†
- å®šæœŸéªŒè¯é…ç½®æ–‡ä»¶çš„è¯­æ³•å’Œé€»è¾‘

### 4. æ–‡æ¡£åŒ–
- ä¸ºæ¯ä¸ªé…ç½®é€‰é¡¹æ·»åŠ æ³¨é‡Š
- ç»´æŠ¤é…ç½®å˜æ›´æ—¥å¿—
- æä¾›ç¤ºä¾‹é…ç½®æ–‡ä»¶

è¿™ä¸ªé…ç½®ç³»ç»Ÿä¸ºINVESTOR-BENCHæä¾›äº†å¼ºå¤§çš„çµæ´»æ€§ï¼ŒåŒæ—¶ä¿è¯äº†ç±»å‹å®‰å…¨å’Œé…ç½®æ­£ç¡®æ€§ã€‚