# ç»Ÿä¸€OpenAIå…¼å®¹APIæ¥å£ä½¿ç”¨æŒ‡å—

## ğŸ¯ é¡¹ç›®é‡æ„æ¦‚è¿°

æœ¬æ¬¡é‡æ„å°†INVESTOR-BENCHé¡¹ç›®ä¸­çš„æ‰€æœ‰LLMå’ŒEmbedding APIè°ƒç”¨ç»Ÿä¸€ä¸ºOpenAIå…¼å®¹æ ¼å¼ï¼Œå®ç°äº†ï¼š

âœ… **ç»Ÿä¸€é…ç½®ç®¡ç†** - æ‰€æœ‰æ¨¡å‹é…ç½®é›†ä¸­åœ¨`config.py`  
âœ… **OpenAIå…¼å®¹æ¥å£** - æ”¯æŒOpenAIã€VLLMã€ç¡…åŸºæµåŠ¨ç­‰å¤šç§Provider  
âœ… **ç®€åŒ–APIè°ƒç”¨** - ç»Ÿä¸€çš„è°ƒç”¨æ–¹å¼ï¼Œæ— éœ€å…³å¿ƒåº•å±‚å®ç°  
âœ… **å‘åå…¼å®¹** - ä¿æŒåŸæœ‰æ¥å£ä¸å˜  
âœ… **çµæ´»æ‰©å±•** - æ˜“äºæ·»åŠ æ–°çš„æ¨¡å‹å’ŒProvider  

## ğŸ“ æ–‡ä»¶ç»“æ„

```
â”œâ”€â”€ config.py                           # ğŸ”¥ ç»Ÿä¸€é…ç½®æ–‡ä»¶
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ chat/endpoint/
â”‚   â”‚   â””â”€â”€ openai_compatible.py        # ğŸ”¥ OpenAIå…¼å®¹LLMå®¢æˆ·ç«¯  
â”‚   â”œâ”€â”€ embedding_unified.py            # ğŸ”¥ ç»Ÿä¸€Embeddingå®¢æˆ·ç«¯
â”‚   â””â”€â”€ embedding.py                    # âœ… æ›´æ–°ä¸ºä½¿ç”¨ç»Ÿä¸€æ¥å£
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ main_unified.json               # ğŸ”¥ ç»Ÿä¸€é…ç½®æ–‡ä»¶ç¤ºä¾‹
â”œâ”€â”€ test_simplified.py                  # âœ… åŸºç¡€åŠŸèƒ½æµ‹è¯•
â”œâ”€â”€ test_openai_compatible.py           # âœ… OpenAIå…¼å®¹æµ‹è¯•
â””â”€â”€ demo_config.json                    # âœ… ç¤ºä¾‹é…ç½®
```

## âš™ï¸ é…ç½®è¯´æ˜

### 1. æ¨¡å‹é…ç½® (config.py)

```python
MODEL_CONFIGS = {
    # ç¡…åŸºæµåŠ¨æ¨¡å‹ (æ¨è)
    "Qwen/Qwen3-8B": {
        "type": "llm_api",
        "model": "Qwen/Qwen3-8B", 
        "api_base": "https://api.siliconflow.cn/v1",
        "api_key": "your-siliconflow-api-key",
        "provider": "siliconflow"
    },
    
    # æœ¬åœ°VLLMæ¨¡å‹
    "local-vllm": {
        "type": "llm_api",
        "model": "meta-llama/Meta-Llama-3.1-8B-Instruct",
        "api_base": "http://0.0.0.0:8000/v1",
        "api_key": "EMPTY",
        "provider": "vllm"
    },
    
    # OpenAIæ¨¡å‹ (å–æ¶ˆæ³¨é‡Šå¹¶é…ç½®å¯†é’¥)
    # "gpt-4": {
    #     "type": "llm_api", 
    #     "model": "gpt-4",
    #     "api_base": "https://api.openai.com/v1",
    #     "api_key": "your-openai-api-key",
    #     "provider": "openai"
    # }
}
```

### 2. è¿è¡Œé…ç½® (configs/main_unified.json)

```json
{
  "chat_config": {
    "chat_model": "Qwen/Qwen3-8B",                    // ğŸ”¥ ä½¿ç”¨config.pyä¸­å®šä¹‰çš„æ¨¡å‹
    "chat_model_inference_engine": "openai_compatible", // ğŸ”¥ ä½¿ç”¨ç»Ÿä¸€æ¥å£
    "chat_system_message": "You are a helpful assistant.",
    "chat_parameters": {
      "temperature": 0.6
    },
    "chat_max_new_token": 1000,
    "chat_request_timeout": 60
  },
  "emb_config": {
    "emb_model_name": "Qwen/Qwen3-Embedding-4B",     // ğŸ”¥ ä½¿ç”¨config.pyä¸­å®šä¹‰çš„Embeddingæ¨¡å‹
    "embedding_timeout": 60
  }
}
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### Step 1: é…ç½®APIå¯†é’¥

åœ¨`config.py`ä¸­é…ç½®æ‚¨çš„APIå¯†é’¥ï¼š

```python
# å°†YOUR_API_KEYæ›¿æ¢ä¸ºå®é™…çš„APIå¯†é’¥
"api_key": "sk-your-actual-api-key-here"
```

### Step 2: é€‰æ‹©è¿è¡Œé…ç½®

ä½¿ç”¨`configs/main_unified.json`æˆ–åˆ›å»ºè‡ªå·±çš„é…ç½®æ–‡ä»¶ï¼š

```bash
# ä½¿ç”¨ç»Ÿä¸€é…ç½®è¿è¡Œ
python run.py --config configs/main_unified.json
```

### Step 3: éªŒè¯é…ç½®

```bash
# è¿è¡ŒåŸºç¡€æµ‹è¯•
python test_simplified.py

# è¿è¡Œè¯¦ç»†æµ‹è¯•  
python test_openai_compatible.py
```

## ğŸ”§ æ”¯æŒçš„Provider

### 1. ç¡…åŸºæµåŠ¨ (æ¨è)

```python
"Qwen/Qwen3-8B": {
    "type": "llm_api",
    "model": "Qwen/Qwen3-8B",
    "api_base": "https://api.siliconflow.cn/v1",
    "api_key": "sk-your-siliconflow-key", 
    "provider": "siliconflow"
}
```

### 2. æœ¬åœ°VLLM

```python  
"local-vllm": {
    "type": "llm_api",
    "model": "your-local-model-name",
    "api_base": "http://localhost:8000/v1",
    "api_key": "EMPTY",
    "provider": "vllm"
}
```

### 3. OpenAIå®˜æ–¹

```python
"gpt-4": {
    "type": "llm_api",
    "model": "gpt-4",
    "api_base": "https://api.openai.com/v1", 
    "api_key": "sk-your-openai-key",
    "provider": "openai"
}
```

### 4. Anthropic (Claude)

```python
"claude-3-sonnet": {
    "type": "llm_api", 
    "model": "claude-3-sonnet-20240229",
    "api_base": "https://api.anthropic.com/v1",
    "api_key": "your-anthropic-key",
    "provider": "anthropic"
}
```

## ğŸ”„ è¿ç§»æŒ‡å—

### ä»æ—§é…ç½®è¿ç§»

1. **åŸæœ‰çš„VLLMé…ç½®**:
   ```json
   // æ—§æ–¹å¼
   "chat_model_inference_engine": "vllm"
   
   // æ–°æ–¹å¼ (æ¨è)
   "chat_model_inference_engine": "openai_compatible"
   "chat_model": "local-vllm"  // åœ¨config.pyä¸­å®šä¹‰
   ```

2. **åŸæœ‰çš„OpenAIé…ç½®**:
   ```json
   // æ—§æ–¹å¼
   "chat_model_inference_engine": "openai"
   
   // æ–°æ–¹å¼ (æ¨è)  
   "chat_model_inference_engine": "openai_compatible"
   "chat_model": "gpt-4"  // åœ¨config.pyä¸­å®šä¹‰
   ```

### å‘åå…¼å®¹

âœ… åŸæœ‰çš„é…ç½®æ–¹å¼ä»ç„¶æ”¯æŒ  
âœ… ç°æœ‰ä»£ç æ— éœ€ä¿®æ”¹  
âœ… å¯ä»¥é€æ­¥è¿ç§»åˆ°æ–°æ¥å£  

## ğŸ› æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **å¯¼å…¥é”™è¯¯**: 
   ```
   ImportError: cannot import name 'ValidChoices'
   ```
   **è§£å†³**: è¿™æ˜¯guardrailsç‰ˆæœ¬å…¼å®¹é—®é¢˜ï¼Œä¸å½±å“æ ¸å¿ƒåŠŸèƒ½ä½¿ç”¨

2. **APIå¯†é’¥é”™è¯¯**:
   ```
   OpenAI API error: Invalid API key
   ```
   **è§£å†³**: æ£€æŸ¥config.pyä¸­çš„APIå¯†é’¥é…ç½®

3. **è¿æ¥è¶…æ—¶**:
   ```
   Connection timeout
   ```
   **è§£å†³**: æ£€æŸ¥api_base URLæ˜¯å¦æ­£ç¡®ï¼Œè°ƒæ•´timeoutè®¾ç½®

### æµ‹è¯•å‘½ä»¤

```bash
# åŸºç¡€åŠŸèƒ½æµ‹è¯•
python test_simplified.py

# è¯¦ç»†åŠŸèƒ½æµ‹è¯•
python test_openai_compatible.py

# è¯­æ³•æ£€æŸ¥
python -m py_compile config.py
python -m py_compile src/embedding_unified.py
```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–

### æ¨èé…ç½®

1. **ç”Ÿäº§ç¯å¢ƒ**: ä½¿ç”¨ç¡…åŸºæµåŠ¨API (ç¨³å®šæ€§å¥½ï¼Œä»·æ ¼ä¾¿å®œ)
2. **å¼€å‘ç¯å¢ƒ**: ä½¿ç”¨æœ¬åœ°VLLM (èŠ‚çœæˆæœ¬ï¼Œå“åº”å¿«)
3. **é«˜è´¨é‡ä»»åŠ¡**: ä½¿ç”¨OpenAI GPT-4 (è´¨é‡æœ€é«˜)

### å‚æ•°è°ƒä¼˜

```json
{
  "chat_parameters": {
    "temperature": 0.6,        // åˆ›é€ æ€§ vs ç¡®å®šæ€§å¹³è¡¡
    "max_tokens": 1000,        // æ ¹æ®ä»»åŠ¡éœ€æ±‚è°ƒæ•´
    "top_p": 0.9,             // è¯æ±‡å¤šæ ·æ€§æ§åˆ¶
    "frequency_penalty": 0.0   // é‡å¤å†…å®¹æƒ©ç½š
  }
}
```

## ğŸ”® æ‰©å±•æŒ‡å—

### æ·»åŠ æ–°Provider

1. åœ¨`config.py`ä¸­æ·»åŠ æ¨¡å‹é…ç½®
2. ç¡®ä¿APIéµå¾ªOpenAIæ ¼å¼
3. æµ‹è¯•è¿æ¥å’Œå“åº”æ ¼å¼
4. æ›´æ–°é…ç½®æ–‡æ¡£

### è‡ªå®šä¹‰å®¢æˆ·ç«¯

```python
from src.chat.endpoint.openai_compatible import OpenAICompatibleClient

# åˆ›å»ºè‡ªå®šä¹‰å®¢æˆ·ç«¯
client = OpenAICompatibleClient("your-model-name")

# è°ƒç”¨API
response = client.chat_completion(
    messages=[{"role": "user", "content": "Hello"}],
    max_tokens=100,
    temperature=0.7
)
```

## ğŸ“ æŠ€æœ¯æ”¯æŒ

å¦‚æœé‡åˆ°é—®é¢˜ï¼š

1. å…ˆè¿è¡Œæµ‹è¯•è„šæœ¬ç¡®è®¤é…ç½®
2. æ£€æŸ¥APIå¯†é’¥å’Œç½‘ç»œè¿æ¥  
3. æŸ¥çœ‹æ—¥å¿—è¾“å‡ºå®šä½é—®é¢˜
4. å‚è€ƒæœ¬æ–‡æ¡£çš„æ•…éšœæ’é™¤éƒ¨åˆ†

---

ğŸ‰ **æ­å–œï¼æ‚¨å·²æˆåŠŸè¿ç§»åˆ°ç»Ÿä¸€çš„OpenAIå…¼å®¹APIç³»ç»Ÿï¼**

ç°åœ¨å¯ä»¥äº«å—ç»Ÿä¸€ã€ç®€æ´ã€é«˜æ•ˆçš„AIæ¨¡å‹è°ƒç”¨ä½“éªŒäº†ï¼